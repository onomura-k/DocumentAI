"""
Layout Parserå˜ä½“ãƒ†ã‚¹ãƒˆ - ãƒ†ã‚­ã‚¹ãƒˆãƒ»æ§‹é€ è§£æç¢ºèªç”¨
Document AI Layout Parserã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã¨æ§‹é€ è§£æã‚’æ¤œè¨¼
"""

import os
import json
import io
from PIL import Image
from google.cloud import documentai_v1beta3 as documentai

class LayoutParserTest:
    """Layout Parserå˜ä½“ãƒ†ã‚¹ãƒˆ"""
    
    def __init__(self):
        self.config = {
            "project_id": "gen-lang-client-0849825641",
            "documentai_location": "us",
            "layout_parser_processor_id": "6af87434352688a1",
            "pdf_path": "sample.pdf"
        }
        
        # Document AI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        self.client = documentai.DocumentProcessorServiceClient()
        
        # ãƒ—ãƒ­ã‚»ãƒƒã‚µåã®æ­£å¼ãªå½¢å¼ã§æ§‹ç¯‰
        self.processor_name = self.client.processor_path(
            self.config['project_id'],
            self.config['documentai_location'], 
            self.config['layout_parser_processor_id']
        )
        
    def get_process_options(self):
        """å…¬å¼ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹æº–æ‹ ã®æ­£ã—ã„LayoutConfigè¨­å®š"""
        from google.cloud import documentai_v1beta3 as documentai
        
        return documentai.ProcessOptions(
            layout_config=documentai.ProcessOptions.LayoutConfig(
                # 1. ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°è¨­å®š
                chunking_config=documentai.ProcessOptions.LayoutConfig.ChunkingConfig(
                    chunk_size=500,
                    include_ancestor_headings=True
                ),
                
                # 2. ğŸ¯ å…¬å¼ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹æº–æ‹ ã®åº§æ¨™ãƒ»ç”»åƒå–å¾—è¨­å®š
                return_images=True,              # ğŸ“‹ å…¬å¼: ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’è¿”å´
                return_bounding_boxes=True,      # ğŸ“‹ å…¬å¼: åº§æ¨™ãƒ‡ãƒ¼ã‚¿(ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹)ã‚’è¿”å´
                
                # 3. è§£æãƒ»æŠ½å‡ºã®æœ‰åŠ¹åŒ–
                enable_llm_layout_parsing=True,  # LLMã«ã‚ˆã‚‹è§£æ
                enable_image_extraction=True,   # ç”»åƒæŠ½å‡º
                enable_image_annotation=True,   # ç”»åƒæ³¨é‡ˆï¼ˆåº§æ¨™å¼·åŒ–ï¼‰
                enable_table_annotation=True    # è¡¨ã®è§£æ
            )
        )
        
    def deep_investigate_bounding_boxes(self, document):
        """Layout Parserç‰¹æœ‰ã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æ ¼ç´å ´æ‰€ã‚’å¾¹åº•èª¿æŸ»"""
        
        print(f"\nğŸ”¬ Layout Parseråº§æ¨™ãƒ‡ãƒ¼ã‚¿å¾¹åº•èª¿æŸ»:")
        print("=" * 60)
        
        coordinates_found = []
        
        # 1. ğŸ“‹ document_layout.blocks ã®ã‚ˆã‚Šæ·±ã„èª¿æŸ»
        if hasattr(document, 'document_layout') and document.document_layout and document.document_layout.blocks:
            print(f"\n1ï¸âƒ£ document_layout.blocks æ·±å±¤èª¿æŸ»:")
            
            for block_idx, block in enumerate(document.document_layout.blocks):
                print(f"\n   ãƒ–ãƒ­ãƒƒã‚¯{block_idx+1} å…¨å±æ€§ã‚¹ã‚­ãƒ£ãƒ³:")
                
                # å…¨å±æ€§ã‚’å¾¹åº•çš„ã«ã‚¹ã‚­ãƒ£ãƒ³
                all_attrs = dir(block)
                relevant_attrs = [attr for attr in all_attrs if not attr.startswith('_')]
                
                print(f"   åˆ©ç”¨å¯èƒ½ãªå…¨å±æ€§: {relevant_attrs}")
                
                # å„å±æ€§ã‚’è©³ç´°ãƒã‚§ãƒƒã‚¯
                for attr in relevant_attrs:
                    try:
                        attr_value = getattr(block, attr)
                        if attr_value is not None:
                            # åº§æ¨™é–¢é€£ã®å±æ€§ã‚’ç‰¹å®š
                            if 'box' in attr.lower() or 'bound' in attr.lower() or 'coord' in attr.lower() or 'vertex' in attr.lower():
                                print(f"   ğŸ¯ åº§æ¨™å€™è£œå±æ€§ç™ºè¦‹: {attr} = {type(attr_value)}")
                                
                                # BoundingPolyã®è©³ç´°èª¿æŸ»
                                if 'BoundingPoly' in str(type(attr_value)):
                                    print(f"      BoundingPolyè©³ç´°èª¿æŸ»:")
                                    poly_attrs = dir(attr_value)
                                    poly_relevant = [pa for pa in poly_attrs if not pa.startswith('_')]
                                    print(f"      åˆ©ç”¨å¯èƒ½å±æ€§: {poly_relevant}")
                                    
                                    for poly_attr in poly_relevant:
                                        try:
                                            poly_value = getattr(attr_value, poly_attr)
                                            if poly_value is not None:
                                                print(f"      {poly_attr}: {type(poly_value)} = {poly_value}")
                                                
                                                # verticesã®è©³ç´°èª¿æŸ»
                                                if 'vertices' in poly_attr and hasattr(poly_value, '__len__'):
                                                    print(f"         verticesé•·ã•: {len(poly_value)}")
                                                    if len(poly_value) > 0:
                                                        for i, vertex in enumerate(poly_value[:4]):  # æœ€åˆã®4å€‹ã®ã¿
                                                            if hasattr(vertex, 'x') and hasattr(vertex, 'y'):
                                                                print(f"         vertex[{i}]: ({vertex.x}, {vertex.y})")
                                            else:
                                                print(f"      {poly_attr}: None")
                                        except Exception as e:
                                            print(f"      {poly_attr}èª¿æŸ»ã‚¨ãƒ©ãƒ¼: {e}")
                                
                                # å±æ€§ã®è©³ç´°èª¿æŸ»
                                if hasattr(attr_value, '__iter__') and not isinstance(attr_value, (str, bytes)):
                                    try:
                                        items = list(attr_value)
                                        print(f"      åå¾©å¯èƒ½ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ: {len(items)}å€‹ã®è¦ç´ ")
                                        if items:
                                            print(f"      æœ€åˆã®è¦ç´ å‹: {type(items[0])}")
                                    except Exception as e:
                                        print(f"      åå¾©èª¿æŸ»ã‚¨ãƒ©ãƒ¼: {e}")
                                
                                # åº§æ¨™ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚’è©¦è¡Œ
                                coords = self._extract_coordinates_from_object(attr_value, f"block_{block_idx+1}.{attr}")
                                if coords:
                                    coordinates_found.extend(coords)
                                    print(f"      âœ… åº§æ¨™ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: {len(coords)}ã‚»ãƒƒãƒˆ")
                            
                            # ç‰¹å®šå±æ€§ã®è©³ç´°èª¿æŸ»
                            elif attr in ['bounding_box', 'page_span', 'text_block', 'image_block']:
                                print(f"   ğŸ“ é‡è¦å±æ€§è©³ç´°: {attr} = {type(attr_value)}")
                                
                                # ã•ã‚‰ã«æ·±ã„éšå±¤ã‚’èª¿æŸ»
                                if hasattr(attr_value, '__dict__') or hasattr(attr_value, '__slots__'):
                                    sub_attrs = dir(attr_value)
                                    coord_sub_attrs = [sub for sub in sub_attrs if not sub.startswith('_')]
                                    print(f"      ã‚µãƒ–å±æ€§: {coord_sub_attrs[:10]}...")
                                    
                                    # ã‚µãƒ–å±æ€§ã‹ã‚‰åº§æ¨™æ¤œç´¢
                                    for sub_attr in coord_sub_attrs:
                                        if 'vertex' in sub_attr.lower() or 'bound' in sub_attr.lower():
                                            try:
                                                sub_value = getattr(attr_value, sub_attr)
                                                if sub_value:
                                                    print(f"      ğŸ¯ ã‚µãƒ–åº§æ¨™å€™è£œ: {attr}.{sub_attr} = {type(sub_value)}")
                                                    coords = self._extract_coordinates_from_object(sub_value, f"block_{block_idx+1}.{attr}.{sub_attr}")
                                                    if coords:
                                                        coordinates_found.extend(coords)
                                                        print(f"      âœ… ã‚µãƒ–åº§æ¨™å–å¾—æˆåŠŸ: {len(coords)}ã‚»ãƒƒãƒˆ")
                                                else:
                                                    print(f"      {attr}.{sub_attr}: ç©ºã¾ãŸã¯None")
                                            except Exception as e:
                                                print(f"      ã‚µãƒ–å±æ€§ã‚¨ãƒ©ãƒ¼: {e}")
                    
                    except Exception as e:
                        print(f"   å±æ€§{attr}èª¿æŸ»ã‚¨ãƒ©ãƒ¼: {e}")
        
        # 2. ğŸ“„ pages æ§‹é€ ã®å†èª¿æŸ»ï¼ˆLayout Parserç‰¹æœ‰ã®å ´æ‰€ã‚’æ¢ã™ï¼‰
        if hasattr(document, 'pages') and document.pages:
            print(f"\n2ï¸âƒ£ document.pages Layout Parserç‰¹åŒ–èª¿æŸ»:")
            
            for page_idx, page in enumerate(document.pages):
                print(f"\n   ãƒšãƒ¼ã‚¸{page_idx+1} å…¨å±æ€§èª¿æŸ»:")
                
                page_attrs = dir(page)
                page_relevant = [attr for attr in page_attrs if not attr.startswith('_')]
                print(f"   ãƒšãƒ¼ã‚¸å±æ€§: {page_relevant}")
                
                # Layout Parserç‰¹æœ‰ã®å±æ€§ã‚’æ¢ã™
                for attr in page_relevant:
                    try:
                        attr_value = getattr(page, attr)
                        if attr_value and hasattr(attr_value, '__len__'):
                            if 'layout' in attr.lower() or 'block' in attr.lower() or 'element' in attr.lower():
                                print(f"   ğŸ¯ Layouté–¢é€£å±æ€§: {attr} = {type(attr_value)}, é•·ã•: {len(attr_value) if hasattr(attr_value, '__len__') else 'N/A'}")
                                
                                # Layouté–¢é€£å±æ€§ã®è©³ç´°èª¿æŸ»
                                if hasattr(attr_value, '__iter__') and len(attr_value) > 0:
                                    first_item = attr_value[0] if attr_value else None
                                    if first_item:
                                        item_attrs = dir(first_item)
                                        coord_attrs = [ia for ia in item_attrs if not ia.startswith('_') and ('bound' in ia.lower() or 'coord' in ia.lower() or 'vertex' in ia.lower())]
                                        if coord_attrs:
                                            print(f"      åº§æ¨™é–¢é€£ã‚µãƒ–å±æ€§ç™ºè¦‹: {coord_attrs}")
                                            
                                            # å®Ÿéš›ã®åº§æ¨™æŠ½å‡º
                                            for coord_attr in coord_attrs:
                                                try:
                                                    coord_value = getattr(first_item, coord_attr)
                                                    coords = self._extract_coordinates_from_object(coord_value, f"page_{page_idx+1}.{attr}[0].{coord_attr}")
                                                    if coords:
                                                        coordinates_found.extend(coords)
                                                        print(f"      âœ… åº§æ¨™å–å¾—æˆåŠŸ: {coord_attr} ã‹ã‚‰ {len(coords)}ã‚»ãƒƒãƒˆ")
                                                except Exception as e:
                                                    print(f"      åº§æ¨™æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
                    except Exception as e:
                        print(f"   ãƒšãƒ¼ã‚¸å±æ€§{attr}ã‚¨ãƒ©ãƒ¼: {e}")
        
        # 3. ğŸ” ãã®ä»–ã®å¯èƒ½ãªåº§æ¨™æ ¼ç´å ´æ‰€
        print(f"\n3ï¸âƒ£ ãã®ä»–ã®åº§æ¨™æ ¼ç´å ´æ‰€èª¿æŸ»:")
        
        # documentç›´ä¸‹ã®ä»–ã®å±æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        doc_attrs = dir(document)
        coord_candidate_attrs = [attr for attr in doc_attrs if not attr.startswith('_') and 
                               ('layout' in attr.lower() or 'bound' in attr.lower() or 'coord' in attr.lower() or 'element' in attr.lower())]
        
        print(f"   åº§æ¨™å€™è£œå±æ€§: {coord_candidate_attrs}")
        
        for attr in coord_candidate_attrs:
            try:
                attr_value = getattr(document, attr)
                if attr_value:
                    print(f"   ğŸ” {attr}: {type(attr_value)}")
                    coords = self._extract_coordinates_from_object(attr_value, f"document.{attr}")
                    if coords:
                        coordinates_found.extend(coords)
                        print(f"   âœ… {attr}ã‹ã‚‰åº§æ¨™å–å¾—: {len(coords)}ã‚»ãƒƒãƒˆ")
            except Exception as e:
                print(f"   {attr}èª¿æŸ»ã‚¨ãƒ©ãƒ¼: {e}")
        
        # çµæœã‚µãƒãƒªãƒ¼
        print(f"\nğŸ“Š Layout Parseråº§æ¨™èª¿æŸ»çµæœ:")
        print(f"   ç™ºè¦‹ã•ã‚ŒãŸåº§æ¨™ã‚»ãƒƒãƒˆ: {len(coordinates_found)}å€‹")
        
        if coordinates_found:
            for i, coord_set in enumerate(coordinates_found):
                print(f"   åº§æ¨™ã‚»ãƒƒãƒˆ{i+1}: {coord_set['source']} - {len(coord_set['coordinates'])}å€‹ã®ç‚¹")
                if coord_set['coordinates']:
                    first_coord = coord_set['coordinates'][0]
                    last_coord = coord_set['coordinates'][-1]
                    print(f"      ç¯„å›²: ({first_coord['x']:.3f}, {first_coord['y']:.3f}) â†’ ({last_coord['x']:.3f}, {last_coord['y']:.3f})")
        else:
            print("   âŒ åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã¯ç™ºè¦‹ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        
        return coordinates_found
    
    def _extract_coordinates_from_object(self, obj, source_path):
        """ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹æ±ç”¨ãƒ¡ã‚½ãƒƒãƒ‰"""
        coordinates = []
        
        try:
            # 1. ç›´æ¥çš„ãªé ‚ç‚¹ãƒªã‚¹ãƒˆ
            if hasattr(obj, 'normalized_vertices') or hasattr(obj, 'vertices'):
                for vertex_attr in ['normalized_vertices', 'vertices']:
                    if hasattr(obj, vertex_attr):
                        vertices = getattr(obj, vertex_attr)
                        if vertices and len(vertices) >= 4:
                            coord_list = []
                            for vertex in vertices:
                                coord_list.append({
                                    "x": getattr(vertex, 'x', 0),
                                    "y": getattr(vertex, 'y', 0)
                                })
                            
                            coordinates.append({
                                "source": f"{source_path}.{vertex_attr}",
                                "coordinates": coord_list
                            })
            
            # 2. ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes)):
                # ãƒªã‚¹ãƒˆã‚„ã‚¿ãƒ—ãƒ«ã®å ´åˆã€å„è¦ç´ ã‚’ãƒã‚§ãƒƒã‚¯
                try:
                    for i, item in enumerate(obj):
                        if hasattr(item, 'normalized_vertices') or hasattr(item, 'vertices'):
                            item_coords = self._extract_coordinates_from_object(item, f"{source_path}[{i}]")
                            coordinates.extend(item_coords)
                except Exception:
                    pass
            
            # 3. åº§æ¨™ã‚‰ã—ãæ•°å€¤å±æ€§ã®çµ„ã¿åˆã‚ã›
            elif hasattr(obj, 'x') and hasattr(obj, 'y'):
                coordinates.append({
                    "source": source_path,
                    "coordinates": [{
                        "x": getattr(obj, 'x', 0),
                        "y": getattr(obj, 'y', 0)
                    }]
                })
            
        except Exception as e:
            print(f"   åº§æ¨™æŠ½å‡ºã‚¨ãƒ©ãƒ¼ ({source_path}): {e}")
        
        return coordinates
        
    def analyze_layout_parser_result(self):
        """Layout Parserçµæœã®è©³ç´°è§£æ"""
        
        print("ğŸ” Layout Parserå˜ä½“ãƒ†ã‚¹ãƒˆé–‹å§‹")
        print("=" * 50)
        
        try:
            # PDFãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            with open(self.config["pdf_path"], "rb") as f:
                pdf_content = f.read()
            
            print(f"ğŸ“ PDFèª­ã¿è¾¼ã¿: {self.config['pdf_path']} ({len(pdf_content)} bytes)")
            
            # ãƒ—ãƒ­ã‚»ãƒƒã‚µæƒ…å ±ã‚’äº‹å‰ç¢ºèª
            self._check_processor_info()
            
            # Layout Parserãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼è¨­å®š
            processor_name = f"projects/{self.config['project_id']}/locations/{self.config['documentai_location']}/processors/{self.config['layout_parser_processor_id']}"
            
            # Document AI ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆé«˜åº¦ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¯¾å¿œç‰ˆï¼‰
            raw_document = documentai.RawDocument(
                content=pdf_content,
                mime_type="application/pdf"
            )
            
            # 1. v1beta3 æœ€æ–°ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®šã‚’å–å¾—
            process_options = self.get_process_options()
            
            # 2. ãƒªã‚¯ã‚¨ã‚¹ãƒˆã« process_options ã‚’å«ã‚ã‚‹
            request = documentai.ProcessRequest(
                name=processor_name,
                raw_document=raw_document,
                process_options=process_options  # â† ã“ã“ãŒé‡è¦ï¼
            )
            
            print("ğŸ”§ v1beta3 å…¬å¼ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹æº–æ‹ è¨­å®š:")
            print(f"   ãƒ—ãƒ­ã‚»ãƒƒã‚µ: Layout Parser (åº§æ¨™ãƒ»ç”»åƒå–å¾—ç‰¹åŒ–)")
            print(f"   âœ… ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°è¨­å®š: chunk_size=500, include_ancestor_headings=True")
            print(f"   ğŸ¯ returnImages: True (LayoutConfigå†… - å…¬å¼æº–æ‹ )")
            print(f"   ğŸ¯ returnBoundingBoxes: True (LayoutConfigå†… - å…¬å¼æº–æ‹ )")
            print(f"   âœ… enableImageAnnotation: True")
            print(f"   âœ… enableImageExtraction: True")
            print(f"   âœ… enableTableAnnotation: True")
            print(f"   âœ… enableLlmLayoutParsing: True (æœ€æ–°Geminiãƒ™ãƒ¼ã‚¹)")
            
            print("ğŸš€ Layout Parserå®Ÿè¡Œä¸­...")
            result = self.client.process_document(request=request)
            document = result.document
            
            print("âœ… Layout Parserå‡¦ç†å®Œäº†\n")
            
            # è©³ç´°è§£æé–‹å§‹
            self._analyze_document_structure(document)
            self._extract_all_text_methods(document) 
            
            # ğŸ†• å€‹åˆ¥ç”»åƒåˆ‡ã‚ŠæŠœãå‡¦ç†ã‚’è¿½åŠ 
            print("\n" + "="*50)
            print("ğŸ–¼ï¸ å€‹åˆ¥ç”»åƒåˆ‡ã‚ŠæŠœãå‡¦ç†")
            print("="*50)
            
            # ğŸ”¬ è©³ç´°èª¿æŸ»ã‚’æœ€åˆã«å®Ÿè¡Œ
            image_block_findings = self.deep_investigate_image_blocks(document)
            
            # ï¿½ Layout Parserç‰¹æœ‰ã®åº§æ¨™ãƒ‡ãƒ¼ã‚¿å¾¹åº•èª¿æŸ»
            layout_coordinates = self.deep_investigate_bounding_boxes(document)
            
            # ï¿½ğŸ¯ é‡è¦: document.pages[].blocks ã®åº§æ¨™èª¿æŸ»ã‚’è¿½åŠ 
            page_blocks_findings = self.investigate_pages_blocks_coordinates(document)
            
            extracted_figures = []
            if hasattr(document, 'pages') and document.pages:
                for page_idx in range(len(document.pages)):
                    # ğŸ†• pages.blocksåº§æ¨™ã‚’ä½¿ã£ãŸåˆ‡ã‚ŠæŠœãã‚’å„ªå…ˆå®Ÿè¡Œ
                    page_figures = self.extract_from_pages_blocks(document, page_idx, page_blocks_findings)
                    extracted_figures.extend(page_figures)
                    
                    # å¾“æ¥ã®æ–¹æ³•ã‚‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ã—ã¦å®Ÿè¡Œ
                    additional_figures = self.extract_individual_images(document, page_idx)
                    extracted_figures.extend(additional_figures)
            else:
                print("âŒ document.pagesãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€å€‹åˆ¥ç”»åƒåˆ‡ã‚ŠæŠœãã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™")
            
            self._save_detailed_results(document, extracted_figures, image_block_findings, layout_coordinates)
            
        except Exception as e:
            print(f"âŒ Layout Parserã‚¨ãƒ©ãƒ¼: {e}")
    
    def _analyze_correct_field_references(self, document):
        """é©åˆ‡ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å‚ç…§ã«ã‚ˆã‚‹è©³ç´°èª¿æŸ» - page_anchor ã‚’ä½¿ã£ãŸæ­£ã—ã„åº§æ¨™å–å¾—"""
        
        print("ğŸ¯ é©åˆ‡ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å‚ç…§è§£æ:")
        print("-" * 50)
        
        analysis_results = {
            "pages_data": [],
            "document_layout_analysis": {},
            "summary": {
                "total_coordinates": 0,
                "total_visual_elements": 0,
                "total_images": 0,
                "coordinate_extraction_success": False,
                "visual_elements_extraction_success": False,
                "image_extraction_success": False
            }
        }
        
        # 1. document.document_layoutè§£æï¼ˆæ§‹é€ ãƒ‡ãƒ¼ã‚¿ï¼‰
        print(f"ğŸ“‹ document.document_layoutè§£æ:")
        layout_blocks_with_coordinates = []
        
        if hasattr(document, 'document_layout') and document.document_layout:
            if hasattr(document.document_layout, 'blocks') and document.document_layout.blocks:
                print(f"   document_layout.blocks: {len(document.document_layout.blocks)}å€‹")
                
                for block_idx, block in enumerate(document.document_layout.blocks):
                    print(f"\n   === ãƒ–ãƒ­ãƒƒã‚¯{block_idx+1} è©³ç´°è§£æ ===")
                    
                    block_info = {
                        "block_id": block_idx + 1,
                        "text": "",
                        "coordinates": [],
                        "page_anchor_info": {},
                        "layout_info": {}
                    }
                    
                    # ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
                    if hasattr(block, 'text_block') and block.text_block:
                        block_info["text"] = block.text_block.text
                        print(f"     ãƒ†ã‚­ã‚¹ãƒˆ: '{block_info['text'][:50]}...'")
                    
                    # ãƒ–ãƒ­ãƒƒã‚¯ã®å…¨å±æ€§ã‚’èª¿æŸ»
                    block_attrs = dir(block)
                    relevant_block_attrs = [attr for attr in block_attrs if not attr.startswith('_')]
                    print(f"     ãƒ–ãƒ­ãƒƒã‚¯å±æ€§: {relevant_block_attrs}")
                    
                    # ğŸ¯ bounding_box ã‚’è©³ç´°èª¿æŸ»ï¼ˆã“ã‚ŒãŒåº§æ¨™ã®æ ¼ç´å ´æ‰€ï¼ï¼‰
                    if hasattr(block, 'bounding_box') and block.bounding_box:
                        bounding_box = block.bounding_box
                        print(f"     âœ… bounding_box: å­˜åœ¨! (ã“ã‚ŒãŒåº§æ¨™ãƒ‡ãƒ¼ã‚¿)")
                        
                        # bounding_boxã®å±æ€§ã‚’èª¿æŸ»
                        bbox_attrs = dir(bounding_box)
                        relevant_bbox_attrs = [attr for attr in bbox_attrs if not attr.startswith('_')]
                        print(f"     bounding_boxå±æ€§: {relevant_bbox_attrs}")
                        
                        # å„bounding_boxå±æ€§ã®å†…å®¹ã‚’ç¢ºèª
                        bbox_data = {}
                        coordinates_extracted = []
                        
                        for attr in relevant_bbox_attrs:
                            try:
                                value = getattr(bounding_box, attr)
                                bbox_data[attr] = str(value)[:100] if value is not None else None
                                print(f"       bounding_box.{attr}: {type(value)} = {str(value)[:200]}...")
                                
                                # åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã‚’è©¦è¡Œ
                                if attr in ['normalized_vertices', 'vertices'] and value:
                                    print(f"       ğŸ¯ {attr}ã‹ã‚‰åº§æ¨™æŠ½å‡ºã‚’è©¦è¡Œ...")
                                    try:
                                        vertices = []
                                        for vertex in value:
                                            vertices.append({
                                                "x": getattr(vertex, 'x', 0),
                                                "y": getattr(vertex, 'y', 0)
                                            })
                                        
                                        coordinates_extracted.append({
                                            "source": f"bounding_box.{attr}",
                                            "coordinates": vertices,
                                            "count": len(vertices)
                                        })
                                        print(f"       âœ… åº§æ¨™å–å¾—æˆåŠŸ: {len(vertices)}å€‹ã®é ‚ç‚¹")
                                    except Exception as e:
                                        print(f"       âŒ åº§æ¨™æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
                                        
                            except Exception as e:
                                print(f"       bounding_box.{attr}: ã‚¨ãƒ©ãƒ¼ - {e}")
                        
                        if coordinates_extracted:
                            block_info["coordinates"] = coordinates_extracted
                            analysis_results["summary"]["total_coordinates"] += sum(c["count"] for c in coordinates_extracted)
                            print(f"     ğŸ¯ ãƒ–ãƒ­ãƒƒã‚¯{block_idx+1} åº§æ¨™å–å¾—æˆåŠŸ: {len(coordinates_extracted)}ã‚»ãƒƒãƒˆ")
                        
                        block_info["bounding_box_info"] = {
                            "has_bounding_box": True,
                            "attributes": relevant_bbox_attrs,
                            "data": bbox_data
                        }
                    else:
                        print(f"     âŒ bounding_box: ãªã—")
                        block_info["bounding_box_info"] = {"has_bounding_box": False}
                    
                    # layoutæƒ…å ±ã‚‚èª¿æŸ»ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
                    if hasattr(block, 'layout') and block.layout:
                        layout = block.layout
                        print(f"     layout: å­˜åœ¨ï¼ˆè¿½åŠ ç¢ºèªï¼‰")
                        
                        # layoutã®å…¨å±æ€§ã‚’èª¿æŸ»
                        layout_attrs = dir(layout)
                        relevant_layout_attrs = [attr for attr in layout_attrs if not attr.startswith('_')]
                        print(f"     layoutå±æ€§: {relevant_layout_attrs}")
                        
                        block_info["layout_info"]["attributes"] = relevant_layout_attrs
                        
                        # page_anchorã‚’ç‰¹ã«è©³ã—ãèª¿æŸ»
                        if hasattr(layout, 'page_anchor') and layout.page_anchor:
                            page_anchor = layout.page_anchor
                            print(f"     âœ… page_anchor: å­˜åœ¨!")
                            
                            # page_anchorã®å±æ€§ã‚’èª¿æŸ»
                            anchor_attrs = dir(page_anchor)
                            relevant_anchor_attrs = [attr for attr in anchor_attrs if not attr.startswith('_')]
                            print(f"     page_anchorå±æ€§: {relevant_anchor_attrs}")
                            
                            block_info["page_anchor_info"] = {
                                "has_page_anchor": True,
                                "attributes": relevant_anchor_attrs
                            }
                        else:
                            print(f"     page_anchor: ãªã—")
                    else:
                        print(f"     layout: ãªã—")
                    
                    layout_blocks_with_coordinates.append(block_info)
            else:
                print(f"   âŒ document_layout.blocksãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        
        analysis_results["document_layout_analysis"] = {
            "blocks_count": len(layout_blocks_with_coordinates),
            "blocks_with_coordinates": layout_blocks_with_coordinates
        }
        
        # 2. document.pagesè§£æï¼ˆç”Ÿãƒ‡ãƒ¼ã‚¿ï¼‰
        if hasattr(document, 'pages') and document.pages:
            print(f"\nğŸ“„ document.pagesè§£æ: {len(document.pages)}ãƒšãƒ¼ã‚¸")
            
            for page_idx, page in enumerate(document.pages):
                print(f"\n  ãƒšãƒ¼ã‚¸ {page_idx + 1}:")
                
                page_data = {
                    "page": page_idx + 1,
                    "coordinates": [],
                    "visual_elements": [],
                    "image_data": {},
                    "raw_elements_count": {}
                }
                
                # ç”Ÿãƒ‡ãƒ¼ã‚¿è¦ç´ ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                for element_type in ['blocks', 'paragraphs', 'lines', 'tokens']:
                    if hasattr(page, element_type):
                        elements = getattr(page, element_type)
                        count = len(elements) if elements else 0
                        page_data["raw_elements_count"][element_type] = count
                        print(f"    {element_type}: {count}å€‹")
                
                # ç”»åƒãƒ‡ãƒ¼ã‚¿ã®å–å¾—
                image_found = self._extract_page_image_data(page, page_data)
                if image_found:
                    analysis_results["summary"]["total_images"] += 1
                
                # ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è¦ç´ ã®å–å¾—
                visual_elements_found = self._extract_page_visual_elements(page, page_data)
                analysis_results["summary"]["total_visual_elements"] += len(page_data["visual_elements"])
                
                analysis_results["pages_data"].append(page_data)
        
        # æˆåŠŸãƒ•ãƒ©ã‚°æ›´æ–°
        analysis_results["summary"]["coordinate_extraction_success"] = analysis_results["summary"]["total_coordinates"] > 0
        analysis_results["summary"]["visual_elements_extraction_success"] = analysis_results["summary"]["total_visual_elements"] > 0
        analysis_results["summary"]["image_extraction_success"] = analysis_results["summary"]["total_images"] > 0
        
        # çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print(f"\nğŸ“Š ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å‚ç…§è§£æçµæœ:")
        print(f"   åº§æ¨™ãƒ‡ãƒ¼ã‚¿: {analysis_results['summary']['total_coordinates']}å€‹ ({'âœ… æˆåŠŸ' if analysis_results['summary']['coordinate_extraction_success'] else 'âŒ å¤±æ•—'})")
        print(f"   ç”»åƒãƒ‡ãƒ¼ã‚¿: {analysis_results['summary']['total_images']}å€‹ ({'âœ… æˆåŠŸ' if analysis_results['summary']['image_extraction_success'] else 'âŒ å¤±æ•—'})")
        print(f"   ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è¦ç´ : {analysis_results['summary']['total_visual_elements']}å€‹ ({'âœ… æˆåŠŸ' if analysis_results['summary']['visual_elements_extraction_success'] else 'âŒ å¤±æ•—'})")
        
        return analysis_results
    
    def _resolve_coordinates_from_page_anchor(self, page_anchor, document):
        """page_anchorã‹ã‚‰åº§æ¨™ã‚’è§£æ±ºï¼ˆãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹æº–æ‹ ã®æ­£ã—ã„æ–¹æ³•ï¼‰"""
        coordinates = []
        
        try:
            # page_anchorã®å„å±æ€§ã‚’ç¢ºèªã—ã¦pageå‚ç…§ã‚’è§£æ±º
            page_refs = []
            
            # ä¸€èˆ¬çš„ãªpageå‚ç…§å±æ€§åã‚’è©¦è¡Œ
            for attr_name in ['page_refs', 'page_ref', 'pages']:
                if hasattr(page_anchor, attr_name):
                    refs = getattr(page_anchor, attr_name)
                    if refs:
                        if hasattr(refs, '__iter__'):  # ãƒªã‚¹ãƒˆã®å ´åˆ
                            page_refs.extend(refs)
                        else:  # å˜ä¸€è¦ç´ ã®å ´åˆ
                            page_refs.append(refs)
            
            # pageå‚ç…§ã‹ã‚‰document.pagesã®å¯¾å¿œã™ã‚‹è¦ç´ ã‚’æ¢ã—ã¦åº§æ¨™ã‚’å–å¾—
            for page_ref in page_refs:
                # page_refã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å±æ€§ã‚’ç¢ºèª
                ref_attrs = dir(page_ref)
                
                # ãƒšãƒ¼ã‚¸ç•ªå·ã‚„è¦ç´ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
                page_num = None
                element_index = None
                
                for attr in ['page', 'page_number', 'page_index']:
                    if hasattr(page_ref, attr):
                        page_num = getattr(page_ref, attr)
                        break
                
                for attr in ['element', 'element_index', 'block_index', 'index']:
                    if hasattr(page_ref, attr):
                        element_index = getattr(page_ref, attr)
                        break
                
                # document.pagesã‹ã‚‰å¯¾å¿œã™ã‚‹è¦ç´ ã‚’å–å¾—
                if page_num is not None and hasattr(document, 'pages') and document.pages:
                    # ãƒšãƒ¼ã‚¸ç•ªå·ã¯1-indexedã®å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚èª¿æ•´
                    page_idx = page_num - 1 if page_num > 0 else page_num
                    
                    if 0 <= page_idx < len(document.pages):
                        page = document.pages[page_idx]
                        
                        # å„è¦ç´ ã‚¿ã‚¤ãƒ—ã‹ã‚‰åº§æ¨™ã‚’å–å¾—
                        for element_type in ['blocks', 'paragraphs', 'lines', 'tokens']:
                            if hasattr(page, element_type):
                                elements = getattr(page, element_type)
                                if elements and element_index is not None and 0 <= element_index < len(elements):
                                    element = elements[element_index]
                                    if hasattr(element, 'layout') and element.layout:
                                        layout = element.layout
                                        if hasattr(layout, 'bounding_poly') and layout.bounding_poly:
                                            bp = layout.bounding_poly
                                            if hasattr(bp, 'normalized_vertices') and bp.normalized_vertices:
                                                vertices = []
                                                for vertex in bp.normalized_vertices:
                                                    vertices.append({
                                                        "x": getattr(vertex, 'x', 0),
                                                        "y": getattr(vertex, 'y', 0)
                                                    })
                                                coordinates.append({
                                                    "source": f"page_{page_num}_{element_type}_{element_index}",
                                                    "coordinates": vertices
                                                })
        except Exception as e:
            print(f"       âš ï¸ page_anchoråº§æ¨™è§£æ±ºã‚¨ãƒ©ãƒ¼: {e}")
        
        return coordinates
    
    def _check_processor_info(self):
        """ãƒ—ãƒ­ã‚»ãƒƒã‚µã®è©³ç´°æƒ…å ±ã‚’å–å¾—ã—ã¦ç¢ºèª"""
        try:
            print("\nğŸ” ãƒ—ãƒ­ã‚»ãƒƒã‚µæƒ…å ±ç¢ºèªä¸­...")
            
            # ãƒ—ãƒ­ã‚»ãƒƒã‚µã®è©³ç´°æƒ…å ±ã‚’å–å¾—
            processor = self.client.get_processor(name=self.processor_name)
            
            print(f"   ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚¿ã‚¤ãƒ—: {processor.type_}")
            print(f"   ãƒ—ãƒ­ã‚»ãƒƒã‚µå: {processor.display_name}")
            print(f"   ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒãƒ¼ã‚¸ãƒ§ãƒ³: {processor.process_endpoint}")
            print(f"   ä½œæˆæ—¥æ™‚: {processor.create_time}")
            print(f"   æœ€çµ‚æ›´æ–°: {processor.update_time}")
            print(f"   çŠ¶æ…‹: {processor.state}")
            
            # ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹æ©Ÿèƒ½ã‚’èª¿æŸ»
            print(f"   ãƒ—ãƒ­ã‚»ãƒƒã‚µID: {processor.name}")
            
        except Exception as e:
            print(f"   âš ï¸  ãƒ—ãƒ­ã‚»ãƒƒã‚µæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _extract_page_coordinates(self, page, page_data, full_text):
        """ãƒšãƒ¼ã‚¸ã‹ã‚‰åº§æ¨™æƒ…å ±ã‚’æŠ½å‡º - è©³ç´°èª¿æŸ»ç‰ˆ"""
        coordinates_found = False
        
        print(f"    ğŸ¯ åº§æ¨™æŠ½å‡º (document.pages[].blocks[].layout.bounding_poly):")
        
        # 1. document.pages[].blocks ã‚’è©³ç´°èª¿æŸ»
        if hasattr(page, 'blocks') and page.blocks:
            print(f"       blocks: {len(page.blocks)}å€‹")
            
            for block_idx, block in enumerate(page.blocks):
                print(f"         ãƒ–ãƒ­ãƒƒã‚¯{block_idx+1}èª¿æŸ»:")
                
                # ãƒ–ãƒ­ãƒƒã‚¯ã®åŸºæœ¬å±æ€§ã‚’ç¢ºèª
                block_attrs = dir(block)
                relevant_attrs = [attr for attr in block_attrs if not attr.startswith('_')]
                print(f"           å±æ€§: {relevant_attrs[:10]}...")  # æœ€åˆã®10å€‹ã®ã¿è¡¨ç¤º
                
                if hasattr(block, 'layout') and block.layout:
                    print(f"           layout: å­˜åœ¨")
                    layout = block.layout
                    
                    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®å±æ€§ã‚‚èª¿æŸ»
                    layout_attrs = dir(layout)
                    layout_relevant = [attr for attr in layout_attrs if not attr.startswith('_')]
                    print(f"           layoutå±æ€§: {layout_relevant[:10]}...")
                    
                    # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒãƒªã‚´ãƒ³ã‚’è©³ç´°èª¿æŸ»
                    if hasattr(layout, 'bounding_poly'):
                        print(f"           bounding_poly: å­˜åœ¨")
                        bounding_poly = layout.bounding_poly
                        
                        if bounding_poly:
                            print(f"           bounding_poly: æœ‰åŠ¹")
                            bp_attrs = dir(bounding_poly)
                            bp_relevant = [attr for attr in bp_attrs if not attr.startswith('_')]
                            print(f"           bounding_polyå±æ€§: {bp_relevant}")
                            
                            # å„é ‚ç‚¹ã‚¿ã‚¤ãƒ—ã‚’ç¢ºèª
                            for vertex_type in ['normalized_vertices', 'vertices']:
                                if hasattr(bounding_poly, vertex_type):
                                    vertices = getattr(bounding_poly, vertex_type)
                                    print(f"           {vertex_type}: {len(vertices) if vertices else 0}å€‹")
                                    
                                    if vertices and len(vertices) > 0:
                                        # åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’å®Ÿéš›ã«å–å¾—
                                        coord_list = []
                                        for vertex in vertices:
                                            coord_list.append({
                                                "x": getattr(vertex, 'x', 0),
                                                "y": getattr(vertex, 'y', 0)
                                            })
                                        
                                        # ãƒ†ã‚­ã‚¹ãƒˆã‚‚åŒæ™‚ã«å–å¾—
                                        block_text = self._extract_text_from_layout(layout, full_text)
                                        
                                        coordinate_entry = {
                                            "block_id": block_idx + 1,
                                            "coordinates": coord_list,
                                            "coordinate_type": vertex_type,
                                            "text": block_text or "",
                                            "text_length": len(block_text) if block_text else 0
                                        }
                                        
                                        page_data["coordinates"].append(coordinate_entry)
                                        coordinates_found = True
                                        
                                        print(f"           âœ… åº§æ¨™å–å¾—æˆåŠŸ: {len(coord_list)}å€‹, ãƒ†ã‚­ã‚¹ãƒˆ'{block_text[:30] if block_text else '(ãªã—)'}...'")
                                        break
                        else:
                            print(f"           bounding_poly: None")
                    else:
                        print(f"           bounding_poly: å±æ€§ãªã—")
                else:
                    print(f"           layout: ãªã—")
        
        # 2. ä»–ã®å¯èƒ½ãªåº§æ¨™ã‚½ãƒ¼ã‚¹ã‚‚èª¿æŸ»
        print(f"\n    ğŸ” ä»–ã®åº§æ¨™ã‚½ãƒ¼ã‚¹èª¿æŸ»:")
        
        # paragraphs
        if hasattr(page, 'paragraphs') and page.paragraphs:
            print(f"       paragraphs: {len(page.paragraphs)}å€‹")
            for i, para in enumerate(page.paragraphs[:3]):  # æœ€åˆã®3å€‹ã®ã¿
                if hasattr(para, 'layout') and para.layout and hasattr(para.layout, 'bounding_poly'):
                    bp = para.layout.bounding_poly
                    if bp and hasattr(bp, 'normalized_vertices') and bp.normalized_vertices:
                        print(f"         æ®µè½{i+1}: åº§æ¨™{len(bp.normalized_vertices)}å€‹ã‚ã‚Š")
        
        # lines
        if hasattr(page, 'lines') and page.lines:
            print(f"       lines: {len(page.lines)}å€‹")
            for i, line in enumerate(page.lines[:3]):  # æœ€åˆã®3å€‹ã®ã¿
                if hasattr(line, 'layout') and line.layout and hasattr(line.layout, 'bounding_poly'):
                    bp = line.layout.bounding_poly
                    if bp and hasattr(bp, 'normalized_vertices') and bp.normalized_vertices:
                        print(f"         è¡Œ{i+1}: åº§æ¨™{len(bp.normalized_vertices)}å€‹ã‚ã‚Š")
        
        # tokens
        if hasattr(page, 'tokens') and page.tokens:
            print(f"       tokens: {len(page.tokens)}å€‹")
            for i, token in enumerate(page.tokens[:3]):  # æœ€åˆã®3å€‹ã®ã¿
                if hasattr(token, 'layout') and token.layout and hasattr(token.layout, 'bounding_poly'):
                    bp = token.layout.bounding_poly
                    if bp and hasattr(bp, 'normalized_vertices') and bp.normalized_vertices:
                        print(f"         ãƒˆãƒ¼ã‚¯ãƒ³{i+1}: åº§æ¨™{len(bp.normalized_vertices)}å€‹ã‚ã‚Š")
        
        if not coordinates_found:
            print(f"       âŒ å…¨ã¦ã®èª¿æŸ»ã§åº§æ¨™æƒ…å ±ãªã—")
        else:
            print(f"       âœ… åº§æ¨™æŠ½å‡ºæˆåŠŸ: {len(page_data['coordinates'])}å€‹")
        
        return coordinates_found
    
    def deep_investigate_image_blocks(self, document):
        """image_block å±æ€§ã®æ§‹é€ ã‚’è©³ç´°ã«èª¿æŸ»ã™ã‚‹"""
        
        print(f"\nğŸ”¬ image_block è©³ç´°æ§‹é€ èª¿æŸ»:")
        print("=" * 50)
        
        if not hasattr(document, 'document_layout') or not document.document_layout.blocks:
            print("âŒ document_layout.blocks ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return []
        
        image_findings = []
        blocks = document.document_layout.blocks
        
        for i, block in enumerate(blocks):
            print(f"\nğŸ“‹ ãƒ–ãƒ­ãƒƒã‚¯ {i+1} èª¿æŸ»:")
            
            # ğŸ¯ image_block ã®å­˜åœ¨ã¨ä¸­èº«ã‚’å¾¹åº•èª¿æŸ»
            if hasattr(block, 'image_block'):
                image_block = getattr(block, 'image_block')
                print(f"   image_block: {bool(image_block)} ({type(image_block)})")
                
                if image_block:  # å®Ÿéš›ã«å€¤ãŒã‚ã‚‹å ´åˆ
                    print(f"   ğŸ“¸ âœ… ãƒ–ãƒ­ãƒƒã‚¯ {i+1} ã¯ image_block ã‚’æŒã£ã¦ã„ã¾ã™ï¼")
                    
                    # image_block ã®å±æ€§ï¼ˆåå‰ï¼‰ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—
                    img_attrs = [a for a in dir(image_block) if not a.startswith('_')]
                    print(f"      å±æ€§ãƒªã‚¹ãƒˆ: {img_attrs}")
                    
                    # å„å±æ€§ã®å€¤ã‚’è©³ç´°èª¿æŸ»
                    image_block_data = {}
                    for attr in img_attrs:
                        try:
                            attr_value = getattr(image_block, attr)
                            attr_type = type(attr_value).__name__
                            
                            # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯é•·ã•ã®ã¿è¡¨ç¤º
                            if isinstance(attr_value, bytes):
                                print(f"      {attr}: {attr_type} ({len(attr_value)} bytes)")
                                image_block_data[attr] = f"bytes_length_{len(attr_value)}"
                            elif isinstance(attr_value, str) and len(attr_value) > 100:
                                print(f"      {attr}: {attr_type} ({len(attr_value)} chars)")
                                image_block_data[attr] = f"string_length_{len(attr_value)}"
                            else:
                                print(f"      {attr}: {attr_type} = {str(attr_value)[:200]}")
                                image_block_data[attr] = str(attr_value)[:200]
                        except Exception as e:
                            print(f"      {attr}: ã‚¨ãƒ©ãƒ¼ - {e}")
                            image_block_data[attr] = f"error: {e}"
                    
                    # ğŸ¯ åº§æ¨™ï¼ˆä½æ‰€ï¼‰ãŒã©ã“ã«ã‚ã‚‹ã‹æ¢ã™
                    coordinates_found = []
                    
                    # æ–¹æ³•1: block.bounding_box ã‹ã‚‰
                    if hasattr(block, 'bounding_box') and block.bounding_box:
                        bbox = block.bounding_box
                        print(f"      ğŸ¯ bounding_box: å­˜åœ¨")
                        
                        for vertex_attr in ['normalized_vertices', 'vertices']:
                            if hasattr(bbox, vertex_attr):
                                vertices = getattr(bbox, vertex_attr)
                                if vertices and len(vertices) >= 4:
                                    coords = [(v.x, v.y) for v in vertices]
                                    coordinates_found.append({
                                        "source": f"block.bounding_box.{vertex_attr}",
                                        "coordinates": coords
                                    })
                                    print(f"         âœ… åº§æ¨™ç™ºè¦‹ ({vertex_attr}): {coords[0]} â†’ {coords[2]}")
                    
                    # æ–¹æ³•2: image_block å†…ã®åº§æ¨™å±æ€§
                    for coord_attr in ['bounding_box', 'bounding_poly', 'layout', 'coordinates']:
                        if hasattr(image_block, coord_attr):
                            coord_obj = getattr(image_block, coord_attr)
                            if coord_obj:
                                print(f"      ğŸ¯ image_block.{coord_attr}: å­˜åœ¨")
                                
                                # åº§æ¨™ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®è©³ç´°èª¿æŸ»
                                if hasattr(coord_obj, 'normalized_vertices'):
                                    vertices = coord_obj.normalized_vertices
                                    if vertices and len(vertices) >= 4:
                                        coords = [(v.x, v.y) for v in vertices]
                                        coordinates_found.append({
                                            "source": f"image_block.{coord_attr}.normalized_vertices",
                                            "coordinates": coords
                                        })
                                        print(f"         âœ… åº§æ¨™ç™ºè¦‹ (image_block): {coords[0]} â†’ {coords[2]}")
                    
                    # ğŸ†• æ–¹æ³•3: blob_assetsã‹ã‚‰ã®å®Ÿç”»åƒãƒ‡ãƒ¼ã‚¿å–å¾—
                    blob_id = getattr(image_block, 'blob_asset_id', '')
                    if blob_id:
                        print(f"      ğŸ¯ blob_asset_id: {blob_id}")
                        
                        # documentã‹ã‚‰blob_assetsã‚’æ¢ã™
                        if hasattr(document, 'blob_assets') and document.blob_assets:
                            for blob_asset in document.blob_assets:
                                if getattr(blob_asset, 'asset_id', '') == blob_id:
                                    print(f"      âœ… blob_assetç™ºè¦‹: {blob_id}")
                                    
                                    # å®Ÿéš›ã®ç”»åƒãƒ‡ãƒ¼ã‚¿å–å¾—
                                    if hasattr(blob_asset, 'content') and blob_asset.content:
                                        image_data = blob_asset.content
                                        mime_type = getattr(blob_asset, 'mime_type', 'image/png')
                                        
                                        # ç”»åƒä¿å­˜
                                        try:
                                            import os
                                            images_dir = "extracted_images"
                                            if not os.path.exists(images_dir):
                                                os.makedirs(images_dir)
                                            
                                            image_filename = f"image_block_{i+1}_{blob_id}.png"
                                            image_path = os.path.join(images_dir, image_filename)
                                            
                                            with open(image_path, 'wb') as f:
                                                f.write(image_data)
                                            
                                            print(f"         âœ… ç”»åƒä¿å­˜æˆåŠŸ: {image_path}")
                                            print(f"         ğŸ“Š ç”»åƒã‚µã‚¤ã‚º: {len(image_data)} bytes")
                                            
                                            # image_block_dataã«è¿½åŠ 
                                            image_block_data['extracted_image_path'] = image_path
                                            image_block_data['extracted_image_size'] = len(image_data)
                                            
                                        except Exception as e:
                                            print(f"         âŒ ç”»åƒä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
                                    break
                    
                    # ãƒ–ãƒ­ãƒƒã‚¯ç¨®é¡ã®å†ç¢ºèª
                    block_type = "unknown"
                    for type_attr in ['type', 'block_type', 'layout_type']:
                        if hasattr(block, type_attr):
                            block_type = getattr(block, type_attr)
                            print(f"      ç¨®é¡ ({type_attr}): {block_type}")
                            break
                    
                    # ç™ºè¦‹æƒ…å ±ã‚’ã¾ã¨ã‚
                    finding = {
                        "block_index": i + 1,
                        "has_image_block": True,
                        "image_block_attributes": img_attrs,
                        "image_block_data": image_block_data,
                        "coordinates_found": coordinates_found,
                        "block_type": block_type,
                        "coordinate_count": len(coordinates_found)
                    }
                    
                    image_findings.append(finding)
                    
                else:
                    print(f"   image_block: False ã¾ãŸã¯ç©º")
            else:
                print(f"   image_block: å±æ€§ãªã—")
            
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯æƒ…å ±ã‚‚å‚è€ƒã¨ã—ã¦è¡¨ç¤º
            if hasattr(block, 'text_block') and block.text_block:
                text_content = getattr(block.text_block, 'text', '')
                print(f"   text_block: ã‚ã‚Š ('{text_content[:30]}...')")
        
        # èª¿æŸ»çµæœã‚µãƒãƒªãƒ¼
        print(f"\nğŸ“Š image_block èª¿æŸ»çµæœ:")
        print(f"   ç·ãƒ–ãƒ­ãƒƒã‚¯æ•°: {len(blocks)}")
        print(f"   image_blockä¿æœ‰: {len(image_findings)}å€‹")
        
        for finding in image_findings:
            print(f"   ãƒ–ãƒ­ãƒƒã‚¯{finding['block_index']}: åº§æ¨™{finding['coordinate_count']}ã‚»ãƒƒãƒˆ, å±æ€§{len(finding['image_block_attributes'])}å€‹")
        
        return image_findings
    
    def investigate_pages_blocks_coordinates(self, document):
        """document.pages[].blocks ã¨ paragraphs ã®åº§æ¨™ã‚’è©³ç´°èª¿æŸ»"""
        
        print(f"\nğŸ¯ pages.blocks åº§æ¨™è©³ç´°èª¿æŸ»:")
        print("=" * 50)
        
        coordinates_findings = []
        
        if not hasattr(document, 'pages') or not document.pages:
            print("âŒ document.pages ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return coordinates_findings
        
        for page_idx, page in enumerate(document.pages):
            print(f"\nğŸ“„ ãƒšãƒ¼ã‚¸ {page_idx + 1} è©³ç´°èª¿æŸ»:")
            
            page_finding = {
                "page_index": page_idx + 1,
                "blocks_with_coordinates": [],
                "paragraphs_with_coordinates": [],
                "lines_with_coordinates": [],
                "tokens_with_coordinates": []
            }
            
            # ğŸ” 1. pages[].blocks ã®å¾¹åº•èª¿æŸ»
            if hasattr(page, 'blocks'):
                blocks = page.blocks
                print(f"   ğŸ“‹ blocks: {len(blocks)}å€‹")
                
                for block_idx, block in enumerate(blocks):
                    print(f"      ãƒ–ãƒ­ãƒƒã‚¯{block_idx+1}:")
                    
                    # ãƒ–ãƒ­ãƒƒã‚¯å±æ€§èª¿æŸ»
                    block_attrs = [attr for attr in dir(block) if not attr.startswith('_')]
                    print(f"        å±æ€§: {block_attrs[:10]}...")
                    
                    # ğŸ¯ layout.bounding_poly ã‚’è©³ç´°èª¿æŸ»
                    if hasattr(block, 'layout') and block.layout:
                        layout = block.layout
                        print(f"        layout: âœ… å­˜åœ¨")
                        
                        if hasattr(layout, 'bounding_poly') and layout.bounding_poly:
                            bp = layout.bounding_poly
                            print(f"        bounding_poly: âœ… å­˜åœ¨")
                            
                            if hasattr(bp, 'normalized_vertices') and bp.normalized_vertices:
                                vertices = bp.normalized_vertices
                                if vertices and len(vertices) >= 4:
                                    coords = [(v.x, v.y) for v in vertices]
                                    print(f"        ğŸ¯ åº§æ¨™ç™ºè¦‹: {coords[0]} â†’ {coords[2]}")
                                    
                                    # ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
                                    block_text = ""
                                    if hasattr(layout, 'text_anchor') and layout.text_anchor:
                                        text_anchor = layout.text_anchor
                                        if hasattr(text_anchor, 'text_segments') and text_anchor.text_segments:
                                            segment = text_anchor.text_segments[0]
                                            start_idx = getattr(segment, 'start_index', 0)
                                            end_idx = getattr(segment, 'end_index', 0)
                                            full_text = getattr(document, 'text', '')
                                            if full_text:
                                                block_text = full_text[start_idx:end_idx]
                                    
                                    block_coord_info = {
                                        "block_index": block_idx + 1,
                                        "coordinates": coords,
                                        "text": block_text,
                                        "source": "pages.blocks.layout.bounding_poly"
                                    }
                                    
                                    page_finding["blocks_with_coordinates"].append(block_coord_info)
                                    print(f"        ãƒ†ã‚­ã‚¹ãƒˆ: '{block_text[:30]}...'")
                                else:
                                    print(f"        normalized_vertices: {len(vertices) if vertices else 0}å€‹ï¼ˆä¸å®Œå…¨ï¼‰")
                            else:
                                print(f"        normalized_vertices: ãªã—")
                        else:
                            print(f"        bounding_poly: ãªã—")
                    else:
                        print(f"        layout: ãªã—")
            else:
                print(f"   ğŸ“‹ blocks: å±æ€§ãªã—")
            
            # ğŸ” 2. pages[].paragraphs ã®å¾¹åº•èª¿æŸ»
            if hasattr(page, 'paragraphs'):
                paragraphs = page.paragraphs
                print(f"   ğŸ“ paragraphs: {len(paragraphs)}å€‹")
                
                for para_idx, paragraph in enumerate(paragraphs):
                    print(f"      æ®µè½{para_idx+1}:")
                    
                    if hasattr(paragraph, 'layout') and paragraph.layout:
                        layout = paragraph.layout
                        print(f"        layout: âœ… å­˜åœ¨")
                        
                        if hasattr(layout, 'bounding_poly') and layout.bounding_poly:
                            bp = layout.bounding_poly
                            if hasattr(bp, 'normalized_vertices') and bp.normalized_vertices:
                                vertices = bp.normalized_vertices
                                if vertices and len(vertices) >= 4:
                                    coords = [(v.x, v.y) for v in vertices]
                                    print(f"        ğŸ¯ æ®µè½åº§æ¨™ç™ºè¦‹: {coords[0]} â†’ {coords[2]}")
                                    
                                    # ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
                                    para_text = ""
                                    if hasattr(layout, 'text_anchor') and layout.text_anchor:
                                        text_anchor = layout.text_anchor
                                        if hasattr(text_anchor, 'text_segments') and text_anchor.text_segments:
                                            segment = text_anchor.text_segments[0]
                                            start_idx = getattr(segment, 'start_index', 0)
                                            end_idx = getattr(segment, 'end_index', 0)
                                            full_text = getattr(document, 'text', '')
                                            if full_text:
                                                para_text = full_text[start_idx:end_idx]
                                    
                                    para_coord_info = {
                                        "paragraph_index": para_idx + 1,
                                        "coordinates": coords,
                                        "text": para_text,
                                        "source": "pages.paragraphs.layout.bounding_poly"
                                    }
                                    
                                    page_finding["paragraphs_with_coordinates"].append(para_coord_info)
                                    print(f"        ãƒ†ã‚­ã‚¹ãƒˆ: '{para_text[:30]}...'")
            else:
                print(f"   ğŸ“ paragraphs: å±æ€§ãªã—")
            
            # ğŸ” 3. pages[].lines ã®èª¿æŸ»ï¼ˆè£œè¶³ï¼‰
            if hasattr(page, 'lines') and page.lines:
                print(f"   ğŸ“ lines: {len(page.lines)}å€‹")
                
                for line_idx, line in enumerate(page.lines[:3]):  # æœ€åˆã®3è¡Œã®ã¿
                    if hasattr(line, 'layout') and line.layout and hasattr(line.layout, 'bounding_poly'):
                        bp = line.layout.bounding_poly
                        if hasattr(bp, 'normalized_vertices') and bp.normalized_vertices:
                            vertices = bp.normalized_vertices
                            if vertices and len(vertices) >= 4:
                                coords = [(v.x, v.y) for v in vertices]
                                
                                line_coord_info = {
                                    "line_index": line_idx + 1,
                                    "coordinates": coords,
                                    "source": "pages.lines.layout.bounding_poly"
                                }
                                
                                page_finding["lines_with_coordinates"].append(line_coord_info)
                                print(f"      è¡Œ{line_idx+1}: åº§æ¨™ã‚ã‚Š")
            
            coordinates_findings.append(page_finding)
        
        # ğŸ¯ èª¿æŸ»çµæœã‚µãƒãƒªãƒ¼
        print(f"\nğŸ“Š pages åº§æ¨™èª¿æŸ»çµæœ:")
        total_blocks_coords = sum(len(pf["blocks_with_coordinates"]) for pf in coordinates_findings)
        total_paras_coords = sum(len(pf["paragraphs_with_coordinates"]) for pf in coordinates_findings)
        total_lines_coords = sum(len(pf["lines_with_coordinates"]) for pf in coordinates_findings)
        
        print(f"   blocksåº§æ¨™: {total_blocks_coords}å€‹")
        print(f"   paragraphsåº§æ¨™: {total_paras_coords}å€‹")
        print(f"   linesåº§æ¨™: {total_lines_coords}å€‹")
        
        return coordinates_findings
    
    def extract_from_pages_blocks(self, document, page_index, page_blocks_findings):
        """pages.blocks ã§è¦‹ã¤ã‹ã£ãŸåº§æ¨™ã‚’ä½¿ã£ã¦å€‹åˆ¥ç”»åƒã‚’åˆ‡ã‚ŠæŠœã"""
        
        print(f"\nğŸ¯ pages.blocksåº§æ¨™ã«ã‚ˆã‚‹ç”»åƒåˆ‡ã‚ŠæŠœã (ãƒšãƒ¼ã‚¸{page_index+1}):")
        print("-" * 50)
        
        extracted_figures = []
        
        # ãƒšãƒ¼ã‚¸å…¨ä½“ç”»åƒã‚’å–å¾—
        if not hasattr(document, 'pages') or page_index >= len(document.pages):
            print("âŒ ãƒšãƒ¼ã‚¸ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return extracted_figures
        
        page = document.pages[page_index]
        if not hasattr(page, 'image') or not page.image or not page.image.content:
            print("âŒ ãƒšãƒ¼ã‚¸ç”»åƒãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return extracted_figures
        
        try:
            # ç”»åƒãƒ‡ãƒ¼ã‚¿å–å¾—
            if isinstance(page.image.content, str):
                import base64
                image_data = base64.b64decode(page.image.content)
            else:
                image_data = page.image.content
            
            whole_image = Image.open(io.BytesIO(image_data))
            width, height = whole_image.size
            
            print(f"âœ… ãƒšãƒ¼ã‚¸å…¨ä½“ç”»åƒ: {width}x{height}px")
            
            # å¯¾å¿œã™ã‚‹ãƒšãƒ¼ã‚¸ã®åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            if page_index < len(page_blocks_findings):
                page_finding = page_blocks_findings[page_index]
                
                # blocksåº§æ¨™ã‹ã‚‰åˆ‡ã‚ŠæŠœã
                blocks_coords = page_finding["blocks_with_coordinates"]
                print(f"ğŸ“‹ blocksåº§æ¨™: {len(blocks_coords)}å€‹")
                
                for block_coord in blocks_coords:
                    coords = block_coord["coordinates"]
                    text = block_coord["text"]
                    
                    # åº§æ¨™ã‚’ãƒ”ã‚¯ã‚»ãƒ«ã«å¤‰æ›
                    left = int(coords[0][0] * width)
                    top = int(coords[0][1] * height)
                    right = int(coords[2][0] * width)
                    bottom = int(coords[2][1] * height)
                    
                    print(f"   ãƒ–ãƒ­ãƒƒã‚¯{block_coord['block_index']}: ({left}, {top}) â†’ ({right}, {bottom})")
                    print(f"   ãƒ†ã‚­ã‚¹ãƒˆ: '{text[:30]}...'")
                    
                    # åº§æ¨™ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
                    if left >= right or top >= bottom or left < 0 or top < 0:
                        print(f"   âŒ ç„¡åŠ¹ãªåº§æ¨™")
                        continue
                    
                    # ç”»åƒåˆ‡ã‚ŠæŠœã
                    try:
                        cropped_img = whole_image.crop((left, top, right, bottom))
                        
                        # ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºä¿
                        figures_dir = "extracted_figures"
                        if not os.path.exists(figures_dir):
                            os.makedirs(figures_dir)
                        
                        # ä¿å­˜
                        save_path = os.path.join(figures_dir, f"block_page{page_index+1}_{block_coord['block_index']}.png")
                        cropped_img.save(save_path)
                        
                        # çµæœè¨˜éŒ²
                        figure_info = {
                            "figure_id": block_coord['block_index'],
                            "coordinates": {
                                "left": left,
                                "top": top,
                                "right": right,
                                "bottom": bottom
                            },
                            "size": {
                                "width": right - left,
                                "height": bottom - top
                            },
                            "text": text,
                            "source": "pages.blocks.layout.bounding_poly",
                            "saved_path": save_path
                        }
                        
                        extracted_figures.append(figure_info)
                        print(f"   âœ… åˆ‡ã‚ŠæŠœãæˆåŠŸ: {save_path}")
                        
                    except Exception as e:
                        print(f"   âŒ åˆ‡ã‚ŠæŠœãã‚¨ãƒ©ãƒ¼: {e}")
                
                # paragraphsåº§æ¨™ã‹ã‚‰ã‚‚åˆ‡ã‚ŠæŠœã
                paras_coords = page_finding["paragraphs_with_coordinates"]
                print(f"ğŸ“ paragraphsåº§æ¨™: {len(paras_coords)}å€‹")
                
                for para_coord in paras_coords:
                    coords = para_coord["coordinates"]
                    text = para_coord["text"]
                    
                    # åº§æ¨™ã‚’ãƒ”ã‚¯ã‚»ãƒ«ã«å¤‰æ›
                    left = int(coords[0][0] * width)
                    top = int(coords[0][1] * height)
                    right = int(coords[2][0] * width)
                    bottom = int(coords[2][1] * height)
                    
                    print(f"   æ®µè½{para_coord['paragraph_index']}: ({left}, {top}) â†’ ({right}, {bottom})")
                    print(f"   ãƒ†ã‚­ã‚¹ãƒˆ: '{text[:30]}...'")
                    
                    # åº§æ¨™ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
                    if left >= right or top >= bottom or left < 0 or top < 0:
                        print(f"   âŒ ç„¡åŠ¹ãªåº§æ¨™")
                        continue
                    
                    # ç”»åƒåˆ‡ã‚ŠæŠœã
                    try:
                        cropped_img = whole_image.crop((left, top, right, bottom))
                        
                        # ä¿å­˜
                        save_path = os.path.join(figures_dir, f"paragraph_page{page_index+1}_{para_coord['paragraph_index']}.png")
                        cropped_img.save(save_path)
                        
                        # çµæœè¨˜éŒ²
                        figure_info = {
                            "figure_id": para_coord['paragraph_index'],
                            "coordinates": {
                                "left": left,
                                "top": top,
                                "right": right,
                                "bottom": bottom
                            },
                            "size": {
                                "width": right - left,
                                "height": bottom - top
                            },
                            "text": text,
                            "source": "pages.paragraphs.layout.bounding_poly",
                            "saved_path": save_path
                        }
                        
                        extracted_figures.append(figure_info)
                        print(f"   âœ… æ®µè½åˆ‡ã‚ŠæŠœãæˆåŠŸ: {save_path}")
                        
                    except Exception as e:
                        print(f"   âŒ æ®µè½åˆ‡ã‚ŠæŠœãã‚¨ãƒ©ãƒ¼: {e}")
            
            print(f"\nğŸ“Š pages.blocksåˆ‡ã‚ŠæŠœãçµæœ: {len(extracted_figures)}å€‹")
            
        except Exception as e:
            print(f"âŒ å…¨ä½“çš„ãªã‚¨ãƒ©ãƒ¼: {e}")
        
        return extracted_figures
    
    def extract_individual_images(self, document, page_index=0):
        """ãƒšãƒ¼ã‚¸å†…ã®å€‹åˆ¥è¦ç´ ï¼ˆæ¤…å­ã‚„äººç‰©ã®ã‚¤ãƒ©ã‚¹ãƒˆï¼‰ã‚’åˆ‡ã‚ŠæŠœã„ã¦ä¿å­˜ã™ã‚‹ - document_layoutå¯¾å¿œç‰ˆ"""
        
        print(f"\nğŸ” å€‹åˆ¥ç”»åƒåˆ‡ã‚ŠæŠœãå‡¦ç†é–‹å§‹ (ãƒšãƒ¼ã‚¸{page_index+1}):")
        print("-" * 40)
        
        extracted_images = []
        
        # 1. ãƒšãƒ¼ã‚¸å…¨ä½“ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ï¼ˆå¾“æ¥é€šã‚Špages[].imageã‹ã‚‰ï¼‰
        if not hasattr(document, 'pages') or not document.pages:
            print("âŒ document.pagesãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return extracted_images
        
        if page_index >= len(document.pages):
            print(f"âŒ ãƒšãƒ¼ã‚¸{page_index+1}ãŒå­˜åœ¨ã—ã¾ã›ã‚“ï¼ˆç·ãƒšãƒ¼ã‚¸æ•°: {len(document.pages)}ï¼‰")
            return extracted_images
        
        page = document.pages[page_index]
        
        if not hasattr(page, 'image') or not page.image or not page.image.content:
            print("âŒ ãƒšãƒ¼ã‚¸ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚return_images=Trueã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return extracted_images
        
        try:
            # base64ãƒ‡ã‚³ãƒ¼ãƒ‰ã¾ãŸã¯ç›´æ¥ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦å‡¦ç†
            if isinstance(page.image.content, str):
                import base64
                image_data = base64.b64decode(page.image.content)
            else:
                image_data = page.image.content
            
            whole_image = Image.open(io.BytesIO(image_data))
            width, height = whole_image.size
            
            print(f"âœ… ãƒšãƒ¼ã‚¸å…¨ä½“ç”»åƒèª­ã¿è¾¼ã¿æˆåŠŸ: {width}x{height}px")
            
            # 2. ğŸ†• document_layout.blocks ã‚’æ¢ç´¢ï¼ˆæœ€æ–°ãƒ—ãƒ­ã‚»ãƒƒã‚µå¯¾å¿œï¼‰
            if not (hasattr(document, 'document_layout') and document.document_layout and 
                   hasattr(document.document_layout, 'blocks') and document.document_layout.blocks):
                print("âŒ document_layout.blocksãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                return extracted_images
            
            blocks = document.document_layout.blocks
            print(f"ğŸ” document_layout.blocksèª¿æŸ»: {len(blocks)}å€‹")
            
            # ğŸ†• ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®ç”»åƒæƒ…å ±èª¿æŸ»ã‚‚è¿½åŠ 
            chunk_image_candidates = []
            if hasattr(document, 'chunked_document') and document.chunked_document:
                chunks = document.chunked_document.chunks
                print(f"ğŸ” chunked_documentè¿½åŠ èª¿æŸ»: {len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯")
                
                for chunk_idx, chunk in enumerate(chunks):
                    # ãƒãƒ£ãƒ³ã‚¯ã«ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    chunk_content = getattr(chunk, 'content', '')
                    if 'image' in chunk_content.lower() or 'figure' in chunk_content.lower() or 'chair' in chunk_content.lower():
                        print(f"  ãƒãƒ£ãƒ³ã‚¯{chunk_idx+1}: ç”»åƒé–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º")
                        chunk_image_candidates.append(chunk_idx)
            
            figure_count = 0
            for i, block in enumerate(blocks):
                print(f"\n  ãƒ–ãƒ­ãƒƒã‚¯{i+1}:")
                
                # ãƒ–ãƒ­ãƒƒã‚¯ã®è©³ç´°å±æ€§ã‚’èª¿æŸ»
                block_attrs = [attr for attr in dir(block) if not attr.startswith('_')]
                print(f"    åˆ©ç”¨å¯èƒ½å±æ€§: {block_attrs[:15]}...")  # æœ€åˆã®15å€‹ã®ã¿è¡¨ç¤º
                
                # ãƒ–ãƒ­ãƒƒã‚¯ã‚¿ã‚¤ãƒ—ã‚’ç¢ºèª
                block_type = None
                for type_attr in ['type', 'block_type', 'layout_type']:
                    if hasattr(block, type_attr):
                        block_type = getattr(block, type_attr)
                        print(f"    {type_attr}: {block_type}")
                        break
                
                # ğŸ¯ figureãƒ–ãƒ­ãƒƒã‚¯ï¼ˆç”»åƒ/å›³è§£ï¼‰ã‚’æ¤œå‡º
                is_figure_block = False
                
                # æ–¹æ³•1: typeãŒ"figure"ã‚„"FIGURE"
                if block_type and str(block_type).lower() in ['figure', 'image']:
                    is_figure_block = True
                    print(f"    âœ… å›³è§£ãƒ–ãƒ­ãƒƒã‚¯æ¤œå‡º: {block_type}")
                
                # æ–¹æ³•2: image_blockã®å­˜åœ¨ç¢ºèª
                elif hasattr(block, 'image_block') and block.image_block:
                    is_figure_block = True
                    print(f"    âœ… image_blockæ¤œå‡º")
                
                # ğŸ†• æ–¹æ³•3: å„ãƒ–ãƒ­ãƒƒã‚¯å±æ€§ã®è©³ç´°èª¿æŸ»ï¼ˆdebugï¼‰
                else:
                    print(f"    ğŸ” ãƒ–ãƒ­ãƒƒã‚¯è©³ç´°èª¿æŸ»:")
                    
                    # å„ãƒ–ãƒ­ãƒƒã‚¯ã‚¿ã‚¤ãƒ—ã®å±æ€§å€¤ã‚’ç¢ºèª
                    for block_type_attr in ['image_block', 'list_block', 'table_block']:
                        if hasattr(block, block_type_attr):
                            attr_value = getattr(block, block_type_attr)
                            print(f"      {block_type_attr}: {bool(attr_value)}")
                            
                            # image_blockãŒå­˜åœ¨ã™ã‚‹å ´åˆã€ã•ã‚‰ã«è©³ç´°ã‚’èª¿æŸ»
                            if block_type_attr == 'image_block' and attr_value:
                                print(f"        image_blockè©³ç´°: {type(attr_value)}")
                                img_attrs = [attr for attr in dir(attr_value) if not attr.startswith('_')]
                                print(f"        image_blockå±æ€§: {img_attrs[:10]}...")
                                is_figure_block = True
                                break
                    
                    # ãƒ†ã‚­ã‚¹ãƒˆä»¥å¤–ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’ç”»åƒå€™è£œã¨ã—ã¦æ‰±ã†
                    if not (hasattr(block, 'text_block') and block.text_block):
                        print(f"    ğŸ” éãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ - ç”»åƒå€™è£œã¨ã—ã¦èª¿æŸ»")
                        is_figure_block = True
                
                if is_figure_block:
                    figure_count += 1
                    print(f"    ğŸ¯ å›³è§£è¦ç´ {figure_count} - åº§æ¨™å–å¾—è©¦è¡Œ")
                    
                    # åº§æ¨™å–å¾—ã®å¤šæ–¹é¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
                    coordinates_found = False
                    coord_source = ""
                    vertices = None
                    
                    # åº§æ¨™å–å¾—æ–¹æ³•1: block.bounding_box
                    if hasattr(block, 'bounding_box') and block.bounding_box:
                        bbox = block.bounding_box
                        print(f"      bounding_box: å­˜åœ¨")
                        
                        # bounding_boxã®è©³ç´°å±æ€§ã‚’èª¿æŸ»
                        bbox_attrs = [attr for attr in dir(bbox) if not attr.startswith('_')]
                        print(f"      bounding_boxå±æ€§: {bbox_attrs}")
                        
                        for vertex_attr in ['normalized_vertices', 'vertices']:
                            if hasattr(bbox, vertex_attr):
                                vertices = getattr(bbox, vertex_attr)
                                if vertices and len(vertices) >= 4:
                                    coordinates_found = True
                                    coord_source = f"bounding_box.{vertex_attr}"
                                    print(f"      âœ… åº§æ¨™å–å¾—æˆåŠŸ: {coord_source}")
                                    break
                                else:
                                    print(f"      bounding_box.{vertex_attr}: {len(vertices) if vertices else 0}å€‹ï¼ˆä¸å®Œå…¨ï¼‰")
                    else:
                        print(f"      bounding_box: ãªã—")
                    
                    # åº§æ¨™å–å¾—æ–¹æ³•2: block.layout.bounding_polyï¼ˆå¾Œæ–¹äº’æ›ï¼‰
                    if not coordinates_found and hasattr(block, 'layout') and block.layout:
                        layout = block.layout
                        print(f"      layout: å­˜åœ¨")
                        
                        if hasattr(layout, 'bounding_poly') and layout.bounding_poly:
                            bp = layout.bounding_poly
                            if hasattr(bp, 'normalized_vertices') and bp.normalized_vertices:
                                vertices = bp.normalized_vertices
                                if vertices and len(vertices) >= 4:
                                    coordinates_found = True
                                    coord_source = "layout.bounding_poly.normalized_vertices"
                                    print(f"      âœ… åº§æ¨™å–å¾—æˆåŠŸ: {coord_source}")
                    
                    if coordinates_found:
                        # å‰²åˆ(0.0-1.0)ã‚’ãƒ”ã‚¯ã‚»ãƒ«(px)ã«å¤‰æ›
                        left = int(vertices[0].x * width)
                        top = int(vertices[0].y * height)
                        right = int(vertices[2].x * width)
                        bottom = int(vertices[2].y * height)
                        
                        # åº§æ¨™ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
                        if left >= right or top >= bottom or left < 0 or top < 0:
                            print(f"      âŒ ç„¡åŠ¹ãªåº§æ¨™: ({left}, {top}) - ({right}, {bottom})")
                            continue
                        
                        print(f"      ğŸ“ åº§æ¨™: å·¦ä¸Š({left}, {top}) â†’ å³ä¸‹({right}, {bottom})")
                        print(f"      ğŸ“ ã‚µã‚¤ã‚º: {right-left}x{bottom-top}px")
                        
                        # 3. ç”»åƒã‚’åˆ‡ã‚ŠæŠœã
                        try:
                            cropped_img = whole_image.crop((left, top, right, bottom))
                            
                            # ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºä¿
                            figures_dir = "extracted_figures"
                            if not os.path.exists(figures_dir):
                                os.makedirs(figures_dir)
                            
                            # ä¿å­˜
                            save_path = os.path.join(figures_dir, f"figure_page{page_index+1}_{figure_count}.png")
                            cropped_img.save(save_path)
                            
                            # çµæœè¨˜éŒ²
                            figure_info = {
                                "figure_id": figure_count,
                                "block_index": i + 1,
                                "coordinates": {
                                    "left": left,
                                    "top": top,
                                    "right": right,
                                    "bottom": bottom
                                },
                                "size": {
                                    "width": right - left,
                                    "height": bottom - top
                                },
                                "coordinate_source": coord_source,
                                "saved_path": save_path
                            }
                            
                            extracted_images.append(figure_info)
                            
                            print(f"      âœ… å€‹åˆ¥ç”»åƒä¿å­˜æˆåŠŸ: {save_path}")
                            
                        except Exception as crop_error:
                            print(f"      âŒ ç”»åƒåˆ‡ã‚ŠæŠœãã‚¨ãƒ©ãƒ¼: {crop_error}")
                    
                    else:
                        print(f"      âŒ åº§æ¨™æƒ…å ±å–å¾—å¤±æ•—")
                
                else:
                    print(f"    â„¹ï¸ ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
            
            print(f"\nğŸ“Š åˆ‡ã‚ŠæŠœãçµæœ:")
            print(f"   ç·ãƒ–ãƒ­ãƒƒã‚¯: {len(blocks)}å€‹")
            print(f"   å›³è§£å€™è£œ: {figure_count}å€‹")
            print(f"   åˆ‡ã‚ŠæŠœãæˆåŠŸ: {len(extracted_images)}å€‹")
            
        except Exception as e:
            print(f"âŒ ç”»åƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        
        return extracted_images
    
    def _extract_page_image_data(self, page, page_data):
        """ãƒšãƒ¼ã‚¸ã‹ã‚‰ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
        
        print(f"    ğŸ–¼ï¸  ç”»åƒæŠ½å‡º (document.pages[].image):")
        
        if hasattr(page, 'image') and page.image:
            image = page.image
            
            # ç”»åƒã®åŸºæœ¬æƒ…å ±
            image_info = {
                "has_content": bool(hasattr(image, 'content') and image.content),
                "content_size": len(image.content) if hasattr(image, 'content') and image.content else 0,
                "mime_type": getattr(image, 'mime_type', ''),
                "width": getattr(image, 'width', 0),
                "height": getattr(image, 'height', 0)
            }
            
            # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            if hasattr(image, 'content') and image.content:
                import base64
                import os
                
                # ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
                images_dir = "extracted_images"
                if not os.path.exists(images_dir):
                    os.makedirs(images_dir)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
                page_num = page_data["page"]
                image_filename = f"layout_parser_page_{page_num}.png"
                image_path = os.path.join(images_dir, image_filename)
                
                try:
                    # base64ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦ä¿å­˜
                    if isinstance(image.content, str):
                        # æ–‡å­—åˆ—ã®å ´åˆã¯base64ãƒ‡ã‚³ãƒ¼ãƒ‰
                        image_data = base64.b64decode(image.content)
                    else:
                        # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯ãã®ã¾ã¾
                        image_data = image.content
                    
                    with open(image_path, 'wb') as f:
                        f.write(image_data)
                    
                    image_info["saved_file"] = image_path
                    image_info["file_saved"] = True
                    
                    print(f"       âœ… ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜æˆåŠŸ: {image_path}")
                    
                except Exception as e:
                    image_info["save_error"] = str(e)
                    image_info["file_saved"] = False
                    print(f"       âŒ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            
            page_data["image_data"] = image_info
            
            print(f"       âœ… ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚ã‚Š:")
            print(f"         ã‚µã‚¤ã‚º: {image_info['content_size']} bytes")
            print(f"         è§£åƒåº¦: {image_info['width']}x{image_info['height']}")
            print(f"         MIME: {image_info['mime_type']}")
            
            return True
        else:
            print(f"       âŒ ç”»åƒãƒ‡ãƒ¼ã‚¿ãªã—")
            page_data["image_data"] = {"has_content": False}
            return False
    
    def _extract_page_visual_elements(self, page, page_data):
        """ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è¦ç´ ã‚’æŠ½å‡º"""
        
        print(f"    ğŸ‘ï¸  ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è¦ç´ æŠ½å‡º (document.pages[].visual_elements):")
        
        visual_elements_found = False
        
        if hasattr(page, 'visual_elements') and page.visual_elements:
            print(f"       visual_elements: {len(page.visual_elements)}å€‹")
            
            for i, element in enumerate(page.visual_elements):
                element_info = {
                    "element_id": i + 1,
                    "type": getattr(element, 'type', ''),
                    "layout": {}
                }
                
                # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæƒ…å ±
                if hasattr(element, 'layout') and element.layout:
                    layout = element.layout
                    
                    if hasattr(layout, 'bounding_poly') and layout.bounding_poly:
                        if hasattr(layout.bounding_poly, 'normalized_vertices') and layout.bounding_poly.normalized_vertices:
                            vertices = []
                            for vertex in layout.bounding_poly.normalized_vertices:
                                vertices.append({
                                    "x": getattr(vertex, 'x', 0),
                                    "y": getattr(vertex, 'y', 0)
                                })
                            element_info["layout"]["coordinates"] = vertices
                
                page_data["visual_elements"].append(element_info)
                visual_elements_found = True
                
                print(f"         è¦ç´ {i+1}: ã‚¿ã‚¤ãƒ—'{element_info['type']}', åº§æ¨™{len(element_info.get('layout', {}).get('coordinates', []))}å€‹")
        
        if not visual_elements_found:
            print(f"       âŒ ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è¦ç´ ãªã—")
        else:
            print(f"       âœ… ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è¦ç´ æŠ½å‡ºæˆåŠŸ: {len(page_data['visual_elements'])}å€‹")
        
        return visual_elements_found
    
    def _analyze_document_structure(self, document):
        """æ–‡æ›¸æ§‹é€ ã®è©³ç´°è§£æ"""
        
        print("ğŸ“‹ Documentæ§‹é€ è§£æ:")
        print("-" * 30)
        
        # åŸºæœ¬å±æ€§ç¢ºèªï¼ˆé«˜åº¦ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰
        attributes = [
            ('text', 'document.text'),
            ('pages', 'document.pages'),
            ('entities', 'document.entities'),
            ('document_layout', 'document.document_layout'),
            ('paragraphs', 'document.paragraphs'),
            ('tables', 'document.tables'),
            ('form_fields', 'document.form_fields'),
            ('chunked_document', 'document.chunked_document'),  # ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°çµæœ
            ('revisions', 'document.revisions'),  # ãƒªãƒ“ã‚¸ãƒ§ãƒ³æƒ…å ±
        ]
        
        for attr, desc in attributes:
            if hasattr(document, attr):
                obj = getattr(document, attr)
                if obj is not None:
                    if isinstance(obj, str):
                        print(f"  âœ… {desc}: {len(obj)}æ–‡å­—")
                        if len(obj) > 0:
                            print(f"     å…ˆé ­50æ–‡å­—: '{obj[:50]}...'")
                    else:
                        try:
                            print(f"  âœ… {desc}: {len(obj)}å€‹ã®è¦ç´ ")
                        except:
                            print(f"  âœ… {desc}: ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå­˜åœ¨ï¼ˆè¦ç´ æ•°å–å¾—ä¸å¯ï¼‰")
                else:
                    print(f"  âš ï¸ {desc}: None")
            else:
                print(f"  âŒ {desc}: å±æ€§ãªã—")
        
        # ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°çµæœã®è©³ç´°ç¢ºèª
        if hasattr(document, 'chunked_document') and document.chunked_document:
            chunks = document.chunked_document.chunks
            print(f"\nğŸ“¦ ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°çµæœè©³ç´°:")
            print(f"   ç·ãƒãƒ£ãƒ³ã‚¯æ•°: {len(chunks)}å€‹")
            
            for i, chunk in enumerate(chunks[:5]):  # æœ€åˆã®5ãƒãƒ£ãƒ³ã‚¯ã®ã¿è¡¨ç¤º
                chunk_text = getattr(chunk, 'content', '')
                chunk_page = getattr(chunk, 'page_headers', [])
                print(f"   ãƒãƒ£ãƒ³ã‚¯{i+1}: {len(chunk_text)}æ–‡å­—")
                if chunk_text:
                    print(f"     å†…å®¹: {chunk_text[:100]}...")
                if chunk_page:
                    print(f"     ãƒšãƒ¼ã‚¸ãƒ˜ãƒƒãƒ€ãƒ¼: {len(chunk_page)}å€‹")
        
        print()
    
    def _extract_all_text_methods(self, document):
        """å…¨ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºæ‰‹æ³•ã‚’è©¦è¡Œ"""
        
        print("ğŸ“„ ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºæ‰‹æ³•æ¯”è¼ƒ:")
        print("-" * 30)
        
        extraction_results = {}
        
        # æ–¹æ³•1: document.text
        if hasattr(document, 'text') and document.text:
            extraction_results['document.text'] = document.text
        else:
            extraction_results['document.text'] = ""
        
        # æ–¹æ³•2: document_layout.blocks
        blocks_text = []
        if hasattr(document, 'document_layout') and document.document_layout:
            print(f"  document_layout.blocks: {len(document.document_layout.blocks)}å€‹")
            for i, block in enumerate(document.document_layout.blocks):
                if hasattr(block, 'text_block') and block.text_block:
                    block_text = block.text_block.text
                    if block_text and block_text.strip():
                        blocks_text.append(block_text.strip())
                        print(f"    ãƒ–ãƒ­ãƒƒã‚¯{i+1}: '{block_text[:30]}...' ({len(block_text)}æ–‡å­—)")
        
        extraction_results['document_layout.blocks'] = "\n".join(blocks_text)
        
        # æ–¹æ³•3: pagesè©³ç´°
        pages_all_text = []
        if hasattr(document, 'pages') and document.pages:
            print(f"  document.pages: {len(document.pages)}ãƒšãƒ¼ã‚¸")
            
            for page_idx, page in enumerate(document.pages):
                print(f"    ãƒšãƒ¼ã‚¸{page_idx+1}:")
                
                # ãƒšãƒ¼ã‚¸ã®å„è¦ç´ ã‚’ç¢ºèª
                page_elements = {
                    'paragraphs': [],
                    'lines': [],
                    'tokens': [],
                    'blocks': []
                }
                
                # æ®µè½
                if hasattr(page, 'paragraphs') and page.paragraphs:
                    print(f"      paragraphs: {len(page.paragraphs)}å€‹")
                    for para in page.paragraphs:
                        if hasattr(para, 'layout') and para.layout:
                            para_text = self._extract_text_from_layout(para.layout, document.text or "")
                            if para_text:
                                page_elements['paragraphs'].append(para_text)
                
                # è¡Œ
                if hasattr(page, 'lines') and page.lines:
                    print(f"      lines: {len(page.lines)}å€‹")
                    for line in page.lines:
                        if hasattr(line, 'layout') and line.layout:
                            line_text = self._extract_text_from_layout(line.layout, document.text or "")
                            if line_text:
                                page_elements['lines'].append(line_text)
                
                # ãƒˆãƒ¼ã‚¯ãƒ³
                if hasattr(page, 'tokens') and page.tokens:
                    print(f"      tokens: {len(page.tokens)}å€‹")
                    token_texts = []
                    for token in page.tokens[:50]:  # æœ€åˆã®50ãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿
                        if hasattr(token, 'layout') and token.layout:
                            token_text = self._extract_text_from_layout(token.layout, document.text or "")
                            if token_text:
                                token_texts.append(token_text)
                    
                    if token_texts:
                        page_elements['tokens'] = [" ".join(token_texts)]
                        print(f"      ãƒˆãƒ¼ã‚¯ãƒ³çµåˆ: '{' '.join(token_texts[:10])}...'")
                
                # ãƒ–ãƒ­ãƒƒã‚¯
                if hasattr(page, 'blocks') and page.blocks:
                    print(f"      blocks: {len(page.blocks)}å€‹")
                    for block in page.blocks:
                        if hasattr(block, 'layout') and block.layout:
                            block_text = self._extract_text_from_layout(block.layout, document.text or "")
                            if block_text:
                                page_elements['blocks'].append(block_text)
                
                # ãƒšãƒ¼ã‚¸å†…ã§æœ€ã‚‚å¤šãã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã—ãŸæ–¹æ³•ã‚’æ¡ç”¨
                best_method = max(page_elements.keys(), key=lambda k: sum(len(text) for text in page_elements[k]))
                if page_elements[best_method]:
                    pages_all_text.extend(page_elements[best_method])
                    print(f"      æ¡ç”¨æ–¹æ³•: {best_method} ({sum(len(text) for text in page_elements[best_method])}æ–‡å­—)")
        
        extraction_results['pages.all'] = "\n".join(pages_all_text)
        
        # çµæœæ¯”è¼ƒ
        print("\nğŸ“Š ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºçµæœæ¯”è¼ƒ:")
        print("-" * 30)
        for method, text in extraction_results.items():
            print(f"  {method}: {len(text)}æ–‡å­—")
            if text and len(text) > 0:
                print(f"    ã‚µãƒ³ãƒ—ãƒ«: '{text[:100]}...'")
        
        # æœ€ã‚‚å¤šãã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ãŸæ–¹æ³•
        best_overall = max(extraction_results.keys(), key=lambda k: len(extraction_results[k]))
        print(f"\nğŸ† æœ€é©ãªæŠ½å‡ºæ–¹æ³•: {best_overall} ({len(extraction_results[best_overall])}æ–‡å­—)")
        
        return extraction_results
    
    def _extract_text_from_layout(self, layout, full_text):
        """ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        try:
            if hasattr(layout, 'text_anchor') and layout.text_anchor:
                text_anchor = layout.text_anchor
                if hasattr(text_anchor, 'text_segments') and text_anchor.text_segments:
                    segment = text_anchor.text_segments[0]
                    start_index = getattr(segment, 'start_index', 0)
                    end_index = getattr(segment, 'end_index', len(full_text))
                    return full_text[start_index:end_index]
        except:
            pass
        return ""
    
    def _save_detailed_results(self, document, extracted_figures=None, image_block_findings=None, layout_coordinates=None):
        """è©³ç´°çµæœã‚’JSONã§ä¿å­˜ - Layout Parseråº§æ¨™èª¿æŸ»çµæœã‚’å«ã‚€"""
        
        # é©åˆ‡ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å‚ç…§è§£æçµæœã‚’å–å¾—
        field_reference_results = self._analyze_correct_field_references(document)
        
        # ğŸ†• å€‹åˆ¥ç”»åƒåˆ‡ã‚ŠæŠœãçµæœã‚’è¿½åŠ 
        individual_images_summary = {
            "total_extracted": len(extracted_figures) if extracted_figures else 0,
            "extraction_success": bool(extracted_figures and len(extracted_figures) > 0),
            "figures_details": extracted_figures if extracted_figures else []
        }
        
        # ğŸ”¬ image_block è©³ç´°èª¿æŸ»çµæœã‚’è¿½åŠ 
        image_block_investigation = {
            "blocks_with_image_block": len(image_block_findings) if image_block_findings else 0,
            "investigation_success": bool(image_block_findings and len(image_block_findings) > 0),
            "detailed_findings": image_block_findings if image_block_findings else []
        }
        
        # ğŸ¯ Layout Parseråº§æ¨™èª¿æŸ»çµæœã‚’è¿½åŠ 
        layout_coordinates_summary = {
            "total_coordinate_sets": len(layout_coordinates) if layout_coordinates else 0,
            "coordinate_extraction_success": bool(layout_coordinates and len(layout_coordinates) > 0),
            "coordinate_sources": layout_coordinates if layout_coordinates else []
        }
        image_block_investigation = {
            "blocks_with_image_block": len(image_block_findings) if image_block_findings else 0,
            "investigation_success": bool(image_block_findings and len(image_block_findings) > 0),
            "detailed_findings": image_block_findings if image_block_findings else []
        }
        
        results = {
            "timestamp": "2026-02-09",
            "processor": "Layout Parser v1beta3 - Coordinate Extraction Optimized",
            "api_version": "documentai_v1beta3",
            "field_reference_strategy": {
                "primary_coordinate_source": "document.pages[].blocks[].layout.bounding_poly",
                "image_data_source": "document.pages[].image", 
                "visual_elements_source": "document.pages[].visual_elements",
                "text_mapping_source": "layout.text_anchor.text_segments"
            },
            "advanced_options": {
                "chunkingConfig": {
                    "enabled": True,
                    "chunk_size": 500,
                    "include_ancestor_headings": True
                },
                "returnImages": True,
                "returnBoundingBoxes": True,
                "enableImageAnnotation": True,
                "enableImageExtraction": True,
                "enableTableAnnotation": True,
                "enableLlmLayoutParsing": False
            },
            "document_analysis": {
                "has_text": hasattr(document, 'text') and bool(document.text),
                "text_length": len(document.text) if hasattr(document, 'text') and document.text else 0,
                "has_pages": hasattr(document, 'pages') and bool(document.pages),
                "pages_count": len(document.pages) if hasattr(document, 'pages') and document.pages else 0,
                "has_document_layout": hasattr(document, 'document_layout') and bool(document.document_layout),
                "blocks_count": len(document.document_layout.blocks) if hasattr(document, 'document_layout') and document.document_layout else 0,
                "has_chunked_document": hasattr(document, 'chunked_document') and bool(document.chunked_document),
                "chunks_count": len(document.chunked_document.chunks) if hasattr(document, 'chunked_document') and document.chunked_document else 0,
                "has_images": hasattr(document, 'images') and bool(document.images),
                "images_count": len(document.images) if hasattr(document, 'images') and document.images else 0
            }
        }
        
        # document_layout.blocksè©³ç´°
        if hasattr(document, 'document_layout') and document.document_layout:
            blocks_detail = []
            for i, block in enumerate(document.document_layout.blocks):
                # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æƒ…å ±ã‚’å–å¾—ï¼ˆæ­£ã—ã„å±æ€§åã‚’ä½¿ç”¨ï¼‰
                bounding_box = None
                if hasattr(block, 'bounding_box') and block.bounding_box:
                    bbox = block.bounding_box
                    if hasattr(bbox, 'normalized_vertices') and bbox.normalized_vertices:
                        # æ­£è¦åŒ–åº§æ¨™ï¼ˆ0-1ã®ç¯„å›²ï¼‰ã‚’å–å¾—
                        vertices = []
                        for vertex in bbox.normalized_vertices:
                            vertices.append({
                                "x": getattr(vertex, 'x', 0),
                                "y": getattr(vertex, 'y', 0)
                            })
                        bounding_box = {
                            "normalized_vertices": vertices
                        }
                    elif hasattr(bbox, 'vertices') and bbox.vertices:
                        # çµ¶å¯¾åº§æ¨™ã‚’å–å¾—
                        vertices = []
                        for vertex in bbox.vertices:
                            vertices.append({
                                "x": getattr(vertex, 'x', 0),
                                "y": getattr(vertex, 'y', 0)
                            })
                        bounding_box = {
                            "vertices": vertices
                        }
                
                block_info = {
                    "block_id": i + 1,
                    "has_text_block": hasattr(block, 'text_block') and bool(block.text_block),
                    "text": block.text_block.text if hasattr(block, 'text_block') and block.text_block else "",
                    "text_length": len(block.text_block.text) if hasattr(block, 'text_block') and block.text_block else 0,
                    "bounding_box": bounding_box  # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æƒ…å ±ã‚’è¿½åŠ 
                }
                blocks_detail.append(block_info)
            
            results["blocks_detail"] = blocks_detail
        
        # ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°çµæœè©³ç´°ï¼ˆé‡è¦ãªæ–°æ©Ÿèƒ½ï¼‰
        if hasattr(document, 'chunked_document') and document.chunked_document:
            chunks_detail = []
            for i, chunk in enumerate(document.chunked_document.chunks):
                chunk_content = getattr(chunk, 'content', '')
                chunk_page_headers = getattr(chunk, 'page_headers', [])
                
                # ãƒãƒ£ãƒ³ã‚¯ã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æƒ…å ±ã‚’å–å¾—
                chunk_bounding_boxes = []
                if hasattr(chunk, 'source_block_ids') and chunk.source_block_ids:
                    # source_block_idsã‚’ç¢ºèª
                    for block_id in chunk.source_block_ids:
                        chunk_bounding_boxes.append({"source_block_id": str(block_id)})
                
                # chunkå†…ã®paragraphsã‹ã‚‰ã‚‚ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æƒ…å ±ã‚’å–å¾—
                paragraphs_with_bbox = []
                if hasattr(chunk, 'chunk_elements') and chunk.chunk_elements:
                    for elem_i, element in enumerate(chunk.chunk_elements):
                        if hasattr(element, 'layout') and element.layout:
                            if hasattr(element.layout, 'bounding_poly') and element.layout.bounding_poly:
                                bbox = element.layout.bounding_poly
                                if hasattr(bbox, 'normalized_vertices') and bbox.normalized_vertices:
                                    vertices = []
                                    for vertex in bbox.normalized_vertices:
                                        vertices.append({
                                            "x": getattr(vertex, 'x', 0),
                                            "y": getattr(vertex, 'y', 0)
                                        })
                                    paragraphs_with_bbox.append({
                                        "element_id": elem_i,
                                        "bounding_box": {"normalized_vertices": vertices}
                                    })
                
                chunk_info = {
                    "chunk_id": i + 1,
                    "content": chunk_content,
                    "content_length": len(chunk_content),
                    "page_headers_count": len(chunk_page_headers),
                    "page_headers": [str(header) for header in chunk_page_headers] if chunk_page_headers else [],
                    "source_blocks": chunk_bounding_boxes,  # ã‚½ãƒ¼ã‚¹ãƒ–ãƒ­ãƒƒã‚¯æƒ…å ±
                    "element_bounding_boxes": paragraphs_with_bbox,  # è¦ç´ ãƒ¬ãƒ™ãƒ«ã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
                    "preview": chunk_content[:200] + "..." if len(chunk_content) > 200 else chunk_content
                }
                chunks_detail.append(chunk_info)
            
            results["chunks_detail"] = chunks_detail
            results["total_chunked_text_length"] = sum(len(getattr(chunk, 'content', '')) for chunk in document.chunked_document.chunks)
        
        # v1beta3 æ–°æ©Ÿèƒ½çµæœã®è©³ç´°è¨˜éŒ²
        
        # imagesæƒ…å ±è©³ç´°
        if hasattr(document, 'images') and document.images:
            images_detail = []
            for i, image in enumerate(document.images):
                image_info = {
                    "image_id": i + 1,
                    "type": type(image).__name__,
                    "has_content": hasattr(image, 'content') and bool(image.content),
                    "content_length": len(image.content) if hasattr(image, 'content') and image.content else 0
                }
                images_detail.append(image_info)
            
            results["images_detail"] = images_detail
        else:
            results["images_detail"] = []
        
        # pagesè©³ç´°æƒ…å ±
        if hasattr(document, 'pages') and document.pages:
            pages_detail = []
            for i, page in enumerate(document.pages):
                page_info = {
                    "page_id": i + 1,
                    "page_number": getattr(page, 'page_number', i + 1),
                    "has_blocks": hasattr(page, 'blocks') and bool(page.blocks),
                    "blocks_count": len(page.blocks) if hasattr(page, 'blocks') and page.blocks else 0,
                    "has_paragraphs": hasattr(page, 'paragraphs') and bool(page.paragraphs),
                    "paragraphs_count": len(page.paragraphs) if hasattr(page, 'paragraphs') and page.paragraphs else 0,
                    "has_lines": hasattr(page, 'lines') and bool(page.lines),
                    "lines_count": len(page.lines) if hasattr(page, 'lines') and page.lines else 0,
                    "has_tables": hasattr(page, 'tables') and bool(page.tables),
                    "tables_count": len(page.tables) if hasattr(page, 'tables') and page.tables else 0
                }
                pages_detail.append(page_info)
            
            results["pages_detail"] = pages_detail
        else:
            results["pages_detail"] = []
        
        # v1beta3 æ©Ÿèƒ½æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼
        results["v1beta3_features_summary"] = {
            "returnImages_detected": bool(hasattr(document, 'images') and document.images),
            "returnBoundingBoxes_detected": False,  # åº§æ¨™æƒ…å ±ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã¯Trueã«æ›´æ–°
            "enableImageAnnotation_active": bool(hasattr(document, 'pages') and document.pages and 
                                                any(hasattr(page, 'image_annotations') and page.image_annotations for page in document.pages)),
            "enableTableAnnotation_active": bool(hasattr(document, 'pages') and document.pages and 
                                               any(hasattr(page, 'tables') and page.tables for page in document.pages)),
            "enableLlmLayoutParsing_active": bool(hasattr(document, 'chunked_document') and document.chunked_document and 
                                                len(document.chunked_document.chunks) > 1)
        }
        
        # é©åˆ‡ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å‚ç…§è§£æçµæœã‚’è¿½åŠ 
        results["analysis_results"] = field_reference_results
        
        # ğŸ†• å€‹åˆ¥ç”»åƒåˆ‡ã‚ŠæŠœãçµæœã‚’è¿½åŠ 
        results["individual_images"] = individual_images_summary
        
        # ğŸ”¬ image_block è©³ç´°èª¿æŸ»çµæœã‚’è¿½åŠ 
        results["image_block_investigation"] = image_block_investigation
        
        # ğŸ¯ Layout Parseråº§æ¨™èª¿æŸ»çµæœã‚’è¿½åŠ 
        results["layout_coordinates_investigation"] = layout_coordinates_summary
        
        # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        output_file = "layout_parser_field_reference_results.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è©³ç´°çµæœä¿å­˜å®Œäº†: {output_file}")
        print(f"   ğŸ“Š è§£æãƒ‡ãƒ¼ã‚¿:")
        print(f"      åº§æ¨™æƒ…å ±: {field_reference_results['summary']['total_coordinates']}å€‹")
        print(f"      ç”»åƒãƒ‡ãƒ¼ã‚¿: {field_reference_results['summary']['total_images']}å€‹") 
        print(f"      ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è¦ç´ : {field_reference_results['summary']['total_visual_elements']}å€‹")
        print(f"      ãƒãƒ£ãƒ³ã‚¯æ•°: {results['document_analysis']['chunks_count']}å€‹")
        print(f"   ğŸ†• å€‹åˆ¥ç”»åƒåˆ‡ã‚ŠæŠœã:")
        print(f"      åˆ‡ã‚ŠæŠœãæˆåŠŸ: {individual_images_summary['total_extracted']}å€‹")
        print(f"   ğŸ”¬ image_block è©³ç´°èª¿æŸ»:")
        print(f"      image_blockä¿æœ‰ãƒ–ãƒ­ãƒƒã‚¯: {image_block_investigation['blocks_with_image_block']}å€‹")
        print(f"   ğŸ¯ Layout Parseråº§æ¨™èª¿æŸ»:")
        print(f"      åº§æ¨™ã‚»ãƒƒãƒˆç™ºè¦‹: {layout_coordinates_summary['total_coordinate_sets']}å€‹")
        
        return results
        bbox_detected = False
        if hasattr(document, 'document_layout') and document.document_layout:
            for block in document.document_layout.blocks:
                if hasattr(block, 'bounding_box') and block.bounding_box:
                    if (hasattr(block.bounding_box, 'normalized_vertices') and block.bounding_box.normalized_vertices) or \
                       (hasattr(block.bounding_box, 'vertices') and block.bounding_box.vertices):
                        bbox_detected = True
                        break
        
        results["v1beta3_features_summary"]["returnBoundingBoxes_detected"] = bbox_detected
        
        # çµæœä¿å­˜
        output_file = "layout_parser_test_results.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ è©³ç´°çµæœä¿å­˜: {output_file}")
        print(f"ğŸ” v1beta3æ©Ÿèƒ½æ¤œè¨¼ã‚µãƒãƒªãƒ¼:")
        print(f"   returnImages: {'âœ… æ¤œå‡º' if results['v1beta3_features_summary']['returnImages_detected'] else 'âŒ ãªã—'}")
        print(f"   returnBoundingBoxes: {'âœ… æ¤œå‡º' if results['v1beta3_features_summary']['returnBoundingBoxes_detected'] else 'âŒ ãªã—'}")
        print(f"   enableLlmLayoutParsing: {'âœ… æœ‰åŠ¹' if results['v1beta3_features_summary']['enableLlmLayoutParsing_active'] else 'âŒ ç„¡åŠ¹'}")
        print(f"   pagesè©³ç´°: {len(results['pages_detail'])}ãƒšãƒ¼ã‚¸")

if __name__ == "__main__":
    tester = LayoutParserTest()
    tester.analyze_layout_parser_result()