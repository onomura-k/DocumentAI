#!/usr/bin/env python3
"""
å®Ÿç”¨çš„ãªãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è§£æ±ºç­–: OCR Processor + Layout Parser
- OCR Processor (d784f2907961b8a6): è©³ç´°åº§æ¨™ãƒ»ãƒ†ã‚­ã‚¹ãƒˆ (1,198æ–‡å­—ãƒ»161åº§æ¨™)
- Layout Parser (6af87434352688a1): é«˜åº¦æ§‹é€ åˆ†æãƒ»ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚° (6ãƒãƒ£ãƒ³ã‚¯)
"""

import json
from google.cloud import documentai_v1beta3 as documentai

class PracticalHybridProcessor:
    def __init__(self):
        """å®Ÿç”¨çš„ãªãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ—ãƒ­ã‚»ãƒƒã‚µåˆæœŸåŒ–"""
        self.project_id = "gen-lang-client-0849825641"
        self.location = "us"
        self.ocr_processor_id = "d784f2907961b8a6"      # æ¤œå‡ºã•ã‚ŒãŸOCR Processor
        self.layout_processor_id = "6af87434352688a1"    # Layout Parser
        
        self.client = documentai.DocumentProcessorServiceClient()
    
    def process_document_complete(self):
        """å®Œå…¨ãªãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ–‡æ›¸å‡¦ç†"""
        print("ğŸ” å®Ÿç”¨çš„ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å‡¦ç†é–‹å§‹")
        print("=" * 60)
        
        pdf_file = "sample.pdf"
        with open(pdf_file, "rb") as pdf:
            pdf_content = pdf.read()
        
        print(f"ğŸ“ PDFèª­ã¿è¾¼ã¿: {pdf_file} ({len(pdf_content)} bytes)")
        
        raw_document = documentai.RawDocument(
            content=pdf_content,
            mime_type="application/pdf"
        )
        
        # 1. OCR Processorã§è©³ç´°åº§æ¨™ãƒ»ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’å–å¾—
        print(f"\nğŸ” Step 1: OCR Processorå‡¦ç†")
        ocr_result = self._process_with_ocr(raw_document)
        
        # 2. Layout Parserã§æ§‹é€ åˆ†æãƒ»ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã‚’å®Ÿè¡Œ
        print(f"ğŸ” Step 2: Layout Parserå‡¦ç†")
        layout_result = self._process_with_layout_parser(raw_document)
        
        # 3. çµæœã‚’çµ±åˆãƒ»ä¿å­˜
        print(f"ğŸ” Step 3: çµæœçµ±åˆãƒ»ä¿å­˜")
        merged_result = self._merge_and_save_results(ocr_result, layout_result)
        
        return merged_result
    
    def _process_with_ocr(self, raw_document):
        """OCR Processorã§è©³ç´°åº§æ¨™ãƒ»ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†"""
        processor_name = f"projects/{self.project_id}/locations/{self.location}/processors/{self.ocr_processor_id}"
        
        request = documentai.ProcessRequest(
            name=processor_name,
            raw_document=raw_document
        )
        
        print("   ğŸš€ OCR Processorå®Ÿè¡Œä¸­...")
        result = self.client.process_document(request=request)
        document = result.document
        
        # OCRçµæœåˆ†æ
        bbox_count = 0
        text_length = len(document.text) if document.text else 0
        pages_count = len(document.pages) if hasattr(document, 'pages') else 0
        
        if hasattr(document, 'pages') and document.pages:
            for page in document.pages:
                if hasattr(page, 'blocks') and page.blocks:
                    for block in page.blocks:
                        if hasattr(block, 'layout') and block.layout and hasattr(block.layout, 'bounding_poly') and block.layout.bounding_poly:
                            if hasattr(block.layout.bounding_poly, 'normalized_vertices') and block.layout.bounding_poly.normalized_vertices:
                                bbox_count += 1
        
        print(f"   âœ… OCR Processorå®Œäº†: {text_length}æ–‡å­—, {bbox_count}åº§æ¨™, {pages_count}ãƒšãƒ¼ã‚¸")
        return document
    
    def _process_with_layout_parser(self, raw_document):
        """Layout Parserã§é«˜åº¦æ§‹é€ åˆ†æå‡¦ç†"""
        processor_name = f"projects/{self.project_id}/locations/{self.location}/processors/{self.layout_processor_id}"
        
        process_options = documentai.ProcessOptions(
            layout_config=documentai.ProcessOptions.LayoutConfig(
                chunking_config=documentai.ProcessOptions.LayoutConfig.ChunkingConfig(
                    chunk_size=500,
                    include_ancestor_headings=True
                ),
                return_images=True,
                return_bounding_boxes=True,
                enable_image_annotation=True,
                enable_image_extraction=True,
                enable_table_annotation=True,
                enable_llm_layout_parsing=True
            )
        )
        
        request = documentai.ProcessRequest(
            name=processor_name,
            raw_document=raw_document,
            process_options=process_options
        )
        
        print("   ğŸš€ Layout Parserå®Ÿè¡Œä¸­...")
        result = self.client.process_document(request=request)
        document = result.document
        
        # Layout Parserçµæœåˆ†æ
        chunks_count = 0
        if hasattr(document, 'chunked_document') and document.chunked_document:
            chunks_count = len(document.chunked_document.chunks)
        
        blocks_count = 0
        if hasattr(document, 'document_layout') and document.document_layout:
            blocks_count = len(document.document_layout.blocks)
        
        print(f"   âœ… Layout Parserå®Œäº†: {chunks_count}ãƒãƒ£ãƒ³ã‚¯, {blocks_count}ãƒ–ãƒ­ãƒƒã‚¯")
        return document
    
    def _merge_and_save_results(self, ocr_document, layout_document):
        """OCRã¨Layout Parserã®çµæœã‚’çµ±åˆã—ã¦ä¿å­˜"""
        
        # çµ±åˆçµæœã®æ§‹ç¯‰
        merged_result = {
            "timestamp": "2026-02-09",
            "processor": "Practical Hybrid: OCR + Layout Parser",
            "processing_strategy": {
                "ocr_processor": {
                    "id": self.ocr_processor_id,
                    "name": "doc-ocr-test", 
                    "purpose": "è©³ç´°åº§æ¨™ãƒ»ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º",
                    "results": {
                        "text_length": len(ocr_document.text) if ocr_document.text else 0,
                        "pages_count": len(ocr_document.pages) if hasattr(ocr_document, 'pages') else 0,
                        "coordinates_available": True
                    }
                },
                "layout_parser": {
                    "id": self.layout_processor_id,
                    "name": "Layout Parser v1beta3",
                    "purpose": "æ§‹é€ åˆ†æãƒ»ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°",
                    "results": {
                        "chunks_count": len(layout_document.chunked_document.chunks) if hasattr(layout_document, 'chunked_document') and layout_document.chunked_document else 0,
                        "blocks_count": len(layout_document.document_layout.blocks) if hasattr(layout_document, 'document_layout') and layout_document.document_layout else 0,
                        "llm_parsing_active": True
                    }
                }
            },
            "hybrid_benefits": [
                "âœ… è©³ç´°ãªåº§æ¨™æƒ…å ± (OCR Processor)",
                "âœ… å®Œå…¨ãªãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º (OCR Processor)", 
                "âœ… é«˜åº¦ãªæ§‹é€ åˆ†æ (Layout Parser)",
                "âœ… ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚° (Layout Parser)",
                "âœ… LLMãƒ™ãƒ¼ã‚¹ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè§£æ (Layout Parser)"
            ]
        }
        
        # OCRè©³ç´°åº§æ¨™æƒ…å ±
        ocr_coordinates = []
        if hasattr(ocr_document, 'pages') and ocr_document.pages:
            for page_idx, page in enumerate(ocr_document.pages):
                if hasattr(page, 'blocks') and page.blocks:
                    for block_idx, block in enumerate(page.blocks):
                        if hasattr(block, 'layout') and block.layout and hasattr(block.layout, 'bounding_poly') and block.layout.bounding_poly:
                            bbox = block.layout.bounding_poly
                            if hasattr(bbox, 'normalized_vertices') and bbox.normalized_vertices:
                                vertices = []
                                for vertex in bbox.normalized_vertices:
                                    vertices.append({
                                        "x": getattr(vertex, 'x', 0),
                                        "y": getattr(vertex, 'y', 0)
                                    })
                                
                                # ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‚‚å–å¾—
                                text_content = ""
                                if hasattr(block, 'layout') and block.layout and hasattr(block.layout, 'text_anchor') and block.layout.text_anchor:
                                    if hasattr(block.layout.text_anchor, 'text_segments') and block.layout.text_anchor.text_segments:
                                        for segment in block.layout.text_anchor.text_segments:
                                            start_idx = getattr(segment, 'start_index', 0)
                                            end_idx = getattr(segment, 'end_index', 0)
                                            if ocr_document.text:
                                                text_content += ocr_document.text[start_idx:end_idx]
                                
                                ocr_coordinates.append({
                                    "page": page_idx + 1,
                                    "block": block_idx + 1,
                                    "coordinates": vertices,
                                    "text": text_content,
                                    "text_length": len(text_content)
                                })
        
        merged_result["ocr_detailed_coordinates"] = ocr_coordinates[:10]  # æœ€åˆã®10å€‹ã®ã‚µãƒ³ãƒ—ãƒ«
        merged_result["ocr_coordinates_summary"] = {
            "total_coordinates": len(ocr_coordinates),
            "sample_count": min(10, len(ocr_coordinates))
        }
        
        # Layout Parser ãƒãƒ£ãƒ³ã‚¯è©³ç´°
        layout_chunks = []
        if hasattr(layout_document, 'chunked_document') and layout_document.chunked_document:
            for i, chunk in enumerate(layout_document.chunked_document.chunks):
                chunk_content = getattr(chunk, 'content', '')
                
                layout_chunks.append({
                    "chunk_id": i + 1,
                    "content": chunk_content,
                    "content_length": len(chunk_content),
                    "preview": chunk_content[:200] + "..." if len(chunk_content) > 200 else chunk_content
                })
        
        merged_result["layout_parser_chunks"] = layout_chunks
        
        # çµ±åˆã‚µãƒãƒªãƒ¼
        merged_result["integration_summary"] = {
            "ocr_text_chars": len(ocr_document.text) if ocr_document.text else 0,
            "ocr_coordinates_count": len(ocr_coordinates),
            "layout_chunks_count": len(layout_chunks),
            "layout_total_chunk_chars": sum(len(getattr(chunk, 'content', '')) for chunk in layout_document.chunked_document.chunks) if hasattr(layout_document, 'chunked_document') and layout_document.chunked_document else 0,
            "processing_success": True,
            "coordinate_extraction_success": len(ocr_coordinates) > 0,
            "chunking_success": len(layout_chunks) > 0
        }
        
        # çµæœä¿å­˜
        output_file = "hybrid_processing_results.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(merged_result, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å‡¦ç†çµæœä¿å­˜: {output_file}")
        print(f"\nğŸ“Š çµ±åˆçµæœã‚µãƒãƒªãƒ¼:")
        print(f"   OCRåº§æ¨™æ•°: {len(ocr_coordinates)}å€‹")
        print(f"   OCRãƒ†ã‚­ã‚¹ãƒˆ: {len(ocr_document.text) if ocr_document.text else 0}æ–‡å­—")
        print(f"   Layout ãƒãƒ£ãƒ³ã‚¯: {len(layout_chunks)}å€‹")
        print(f"   åº§æ¨™å–å¾—: {'âœ… æˆåŠŸ' if len(ocr_coordinates) > 0 else 'âŒ å¤±æ•—'}")
        print(f"   ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°: {'âœ… æˆåŠŸ' if len(layout_chunks) > 0 else 'âŒ å¤±æ•—'}")
        
        return merged_result

if __name__ == "__main__":
    processor = PracticalHybridProcessor()
    result = processor.process_document_complete()