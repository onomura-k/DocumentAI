#!/usr/bin/env python3
"""
Google Cloud Document AI - Form Parserå°‚ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
åº§æ¨™ä»˜ããƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã€ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ§‹é€ è§£æã€ç”»åƒå–å¾—
Document OCRã¨ã®æ¯”è¼ƒæ¤œè¨¼ç”¨
"""

import json
import base64
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional
import io

try:
    from google.cloud import documentai_v1 as documentai
    from google.api_core.client_options import ClientOptions
    from PIL import Image, ImageDraw
except ImportError as e:
    print(f"âŒ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“: {e}")
    print("ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
    print("pip install google-cloud-documentai pillow")
    exit(1)


class FormParserProcessor:
    """Form Parserãƒ—ãƒ­ã‚»ãƒƒã‚µã«ã‚ˆã‚‹åŒ…æ‹¬çš„æ–‡æ›¸è§£æ"""
    
    def __init__(self):
        # è¨­å®šæƒ…å ±
        self.config = {
            "project_id": "gen-lang-client-0849825641",
            "location": "us",  # Form Parserãƒ—ãƒ­ã‚»ãƒƒã‚µã®ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³
            "form_parser_processor_id": "338ea0ecd68b764b",  # Form Parserãƒ—ãƒ­ã‚»ãƒƒã‚µ
            "pdf_path": "sample.pdf",
            "output_dir": "form_parser_images"
        }
        
        # Form Parserå°‚ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ï¼ˆãƒªãƒ¼ã‚¸ãƒ§ãƒ³åˆ¥ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼‰
        opts = ClientOptions(api_endpoint=f"{self.config['location']}-documentai.googleapis.com")
        self.client = documentai.DocumentProcessorServiceClient(client_options=opts)
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        Path(self.config["output_dir"]).mkdir(exist_ok=True)
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ç”¨ï¼ˆæ¯”è¼ƒç”¨ã¨ã—ã¦åŒã˜ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ï¼‰
        self.chair_keywords = [
            'ã‚¨ãƒƒã‚°ãƒã‚§ã‚¢', 'ã‚¢ãƒ³ãƒˆãƒã‚§ã‚¢', 'ã‚¹ãƒ¯ãƒ³ãƒã‚§ã‚¢', 'ã‚»ãƒ–ãƒ³ãƒã‚§ã‚¢',
            'ãƒ™ãƒ«ãƒ“ãƒ¥ãƒ¼ãƒ»ãƒã‚§ã‚¢', 'ã‚¢ãƒªãƒ³ã‚³ãƒã‚§ã‚¢'
        ]
        
        # æ¨å®šã‚¨ãƒªã‚¢ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆè¨­å®š
        self.area_offset = {
            'top': 0.1,     # ä¸Šæ–¹å‘10%
            'bottom': 0.1,  # ä¸‹æ–¹å‘10%
            'left': 0.15,   # å·¦æ–¹å‘15%
            'right': 0.15   # å³æ–¹å‘15%
        }
    
    def get_process_options(self):
        """Form Parserç”¨ã®ProcessOptionsè¨­å®šï¼ˆåŸºæœ¬è¨­å®šã®ã¿ï¼‰"""
        # Form Parserã§ã¯åŸºæœ¬çš„ãªOCRè¨­å®šã®ã¿ã‚’ä½¿ç”¨
        return None  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨
    
    def analyze_document_with_form_parser(self):
        """Form Parserãƒ—ãƒ­ã‚»ãƒƒã‚µã«ã‚ˆã‚‹åŒ…æ‹¬çš„æ–‡æ›¸è§£æ"""
        
        print("ğŸ” Form Parser åŒ…æ‹¬çš„è§£æé–‹å§‹")
        print("=" * 60)
        
        results = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "processor_type": "Form Parser",
            "processor_id": self.config["form_parser_processor_id"],
            "full_text": "",
            "text_blocks": [],
            "paragraphs": [],
            "lines": [],
            "tokens": [],
            "visual_elements": [],
            "form_fields": [],
            "tables": [],
            "extracted_figures": [],
            "page_images": [],
            "summary": {
                "total_pages": 0,
                "total_blocks": 0,
                "total_paragraphs": 0,
                "total_lines": 0,
                "total_tokens": 0,
                "total_form_fields": 0,
                "total_tables": 0,
                "total_figures": 0,
                "coordinates_found": 0,
                "images_saved": 0
            }
        }
        
        try:
            # ğŸ”¹ 1. PDFèª­ã¿è¾¼ã¿
            pdf_path = Path(self.config["pdf_path"])
            if not pdf_path.exists():
                raise FileNotFoundError(f"PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pdf_path}")
            
            with open(pdf_path, "rb") as pdf_file:
                pdf_content = pdf_file.read()
            
            print(f"ğŸ“ PDFèª­ã¿è¾¼ã¿: {pdf_path.name} ({len(pdf_content):,} bytes)")
            
            # ğŸ”¹ 2. Form Parserå®Ÿè¡Œ
            processor_name = self.client.processor_path(
                self.config["project_id"], 
                self.config["location"], 
                self.config["form_parser_processor_id"]
            )
            
            raw_document = documentai.RawDocument(
                content=pdf_content, 
                mime_type="application/pdf"
            )
            
            print("ğŸš€ Form Parser å®Ÿè¡Œä¸­...")
            
            # ProcessOptionsã‚’é©ç”¨
            process_options = self.get_process_options()
            
            request = documentai.ProcessRequest(
                name=processor_name,
                raw_document=raw_document,
                process_options=process_options
            )
            
            # Document AIå®Ÿè¡Œ
            result = self.client.process_document(request=request)
            document = result.document
            
            print("âœ… Form Parser å‡¦ç†å®Œäº†\n")
            
            # ğŸ”¹ 3. å…¨ä½“ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
            results["full_text"] = document.text
            print(f"ğŸ“„ å…¨ãƒ†ã‚­ã‚¹ãƒˆå–å¾—: {len(document.text):,}æ–‡å­—")
            
            # ğŸ”¹ 4. Form Parserç‰¹æœ‰ã®è¦ç´ è§£æ
            if hasattr(document, 'entities') and document.entities:
                print(f"ğŸ“‹ ãƒ•ã‚©ãƒ¼ãƒ è¦ç´ : {len(document.entities)}å€‹")
                for entity_idx, entity in enumerate(document.entities):
                    field_data = self._extract_form_field(entity, document.text, entity_idx + 1)
                    if field_data:
                        results["form_fields"].append(field_data)
                        results["summary"]["total_form_fields"] += 1
            
            # ğŸ”¹ 5. ãƒ†ãƒ¼ãƒ–ãƒ«è§£æ
            if hasattr(document, 'pages') and document.pages:
                for page_idx, page in enumerate(document.pages):
                    if hasattr(page, 'tables') and page.tables:
                        print(f"ğŸ“Š ãƒ†ãƒ¼ãƒ–ãƒ«: {len(page.tables)}å€‹ï¼ˆãƒšãƒ¼ã‚¸{page_idx + 1}ï¼‰")
                        for table_idx, table in enumerate(page.tables):
                            table_data = self._extract_table_data(table, document.text, page_idx + 1, table_idx + 1)
                            if table_data:
                                results["tables"].append(table_data)
                                results["summary"]["total_tables"] += 1
            
            # ğŸ”¹ 6. ãƒšãƒ¼ã‚¸åˆ¥è©³ç´°è§£æ
            if hasattr(document, 'pages') and document.pages:
                results["summary"]["total_pages"] = len(document.pages)
                print(f"ğŸ“‹ ãƒšãƒ¼ã‚¸æ•°: {len(document.pages)}å€‹\n")
                
                for page_idx, page in enumerate(document.pages):
                    print(f"--- ãƒšãƒ¼ã‚¸ {page_idx + 1} è§£æï¼ˆForm Parserï¼‰---")
                    
                    # ğŸ¯ 6-1. ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã¨åº§æ¨™æŠ½å‡º
                    if hasattr(page, 'blocks') and page.blocks:
                        print(f"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯: {len(page.blocks)}å€‹")
                        
                        for block_idx, block in enumerate(page.blocks):
                            block_data = self._extract_text_block_with_coordinates(
                                block, document.text, page_idx + 1, block_idx + 1
                            )
                            if block_data:
                                results["text_blocks"].append(block_data)
                                results["summary"]["total_blocks"] += 1
                                if block_data["coordinates"]:
                                    results["summary"]["coordinates_found"] += 1
                                
                                print(f"  ãƒ–ãƒ­ãƒƒã‚¯{block_idx + 1}: '{block_data['text'][:30]}...' "
                                      f"åº§æ¨™: {'âœ…' if block_data['coordinates'] else 'âŒ'}")
                    
                    # ğŸ¯ 6-2. æ®µè½è§£æ
                    if hasattr(page, 'paragraphs') and page.paragraphs:
                        print(f"ğŸ“ æ®µè½: {len(page.paragraphs)}å€‹")
                        for para_idx, paragraph in enumerate(page.paragraphs):
                            para_data = self._extract_text_element_with_coordinates(
                                paragraph, document.text, page_idx + 1, para_idx + 1, "paragraph"
                            )
                            if para_data:
                                results["paragraphs"].append(para_data)
                                results["summary"]["total_paragraphs"] += 1
                    
                    # ğŸ¯ 6-3. è¡Œè§£æ
                    if hasattr(page, 'lines') and page.lines:
                        print(f"ğŸ“ è¡Œ: {len(page.lines)}å€‹")
                        for line_idx, line in enumerate(page.lines[:10]):  # æœ€åˆã®10è¡Œã®ã¿è¡¨ç¤º
                            line_data = self._extract_text_element_with_coordinates(
                                line, document.text, page_idx + 1, line_idx + 1, "line"
                            )
                            if line_data:
                                results["lines"].append(line_data)
                                results["summary"]["total_lines"] += 1
                        
                        if len(page.lines) > 10:
                            print(f"     ... ä»– {len(page.lines) - 10} è¡Œ")
                    
                    # ğŸ¯ 6-4. ãƒˆãƒ¼ã‚¯ãƒ³è§£æ
                    if hasattr(page, 'tokens') and page.tokens:
                        print(f"ğŸ”¤ ãƒˆãƒ¼ã‚¯ãƒ³: {len(page.tokens)}å€‹")
                        for token_idx, token in enumerate(page.tokens[:15]):  # æœ€åˆã®15ãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿
                            token_data = self._extract_text_element_with_coordinates(
                                token, document.text, page_idx + 1, token_idx + 1, "token"
                            )
                            if token_data:
                                results["tokens"].append(token_data)
                                results["summary"]["total_tokens"] += 1
                        
                        if len(page.tokens) > 15:
                            print(f"     ... ä»– {len(page.tokens) - 15} ãƒˆãƒ¼ã‚¯ãƒ³")
                    
                    # ğŸ¯ 6-5. è¦–è¦šçš„è¦ç´ ã¨åº§æ¨™æŠ½å‡ºï¼ˆè©³ç´°èª¿æŸ»ä»˜ãï¼‰
                    print(f"\nğŸ” visual_elements è©³ç´°èª¿æŸ»ï¼ˆForm Parserï¼‰:")
                    
                    if hasattr(page, 'visual_elements'):
                        visual_elements = page.visual_elements
                        print(f"   visual_elementså±æ€§: å­˜åœ¨")
                        print(f"   visual_elementså‹: {type(visual_elements)}")
                        print(f"   visual_elementsé•·ã•: {len(visual_elements) if visual_elements else 0}")
                        
                        if visual_elements and len(visual_elements) > 0:
                            print(f"ğŸ–¼ï¸ è¦–è¦šçš„è¦ç´ : {len(visual_elements)}å€‹")
                            
                            for elem_idx, element in enumerate(visual_elements):
                                elem_data = self._extract_visual_element_with_coordinates(
                                    element, page_idx + 1, elem_idx + 1
                                )
                                if elem_data:
                                    results["visual_elements"].append(elem_data)
                                    
                                    if elem_data["type"] == "figure":
                                        results["summary"]["total_figures"] += 1
                                        print(f"     âœ… å›³è¡¨ã¨ã—ã¦èªè­˜: '{elem_data['type']}'")
                                    else:
                                        print(f"     ğŸ“Š ãã®ä»–è¦ç´ : '{elem_data['type']}'")
                        else:
                            print(f"   âš ï¸ visual_elementsé…åˆ—ã¯å­˜åœ¨ã™ã‚‹ãŒç©ºã§ã™")
                            
                            # ğŸ¯ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã«ã‚ˆã‚‹æ¨å®šç”»åƒã‚¨ãƒªã‚¢æŠ½å‡º
                            print(f"\nğŸ¯ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢: æ¤…å­é–¢é€£ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã‚¨ãƒªã‚¢ã‚’æ¨å®š")
                            self._extract_estimated_image_areas_by_keywords(page, results, page_idx + 1, document.text)
                    else:
                        print(f"   âŒ visual_elementså±æ€§ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                    
                    # ğŸ¯ 6-6. ãƒšãƒ¼ã‚¸ç”»åƒä¿å­˜
                    if hasattr(page, 'image') and page.image:
                        page_image_info = self._save_page_image(page, page_idx + 1)
                        if page_image_info:
                            results["page_images"].append(page_image_info)
                            results["summary"]["images_saved"] += 1
                            print(f"ğŸ’¾ ãƒšãƒ¼ã‚¸ç”»åƒä¿å­˜: {page_image_info['filename']}")
                    
                    print()  # ç©ºè¡Œ
            
            # ğŸ”¹ 7. å›³è¡¨ã®å€‹åˆ¥åˆ‡ã‚ŠæŠœãå®Ÿè¡Œ
            print("ğŸ”„ å›³è¡¨åˆ‡ã‚ŠæŠœãå‡¦ç†é–‹å§‹...")
            self._extract_figure_images(results)
            
            # ğŸ”¹ 8. çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º
            self._display_summary(results)
            
            # ğŸ”¹ 9. çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            output_file = f"form_parser_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ çµæœä¿å­˜å®Œäº†: {output_file}")
            
            return results
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return None
    
    def _extract_form_field(self, entity, full_text: str, field_num: int) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        
        field_data = {
            "field_id": field_num,
            "type": str(entity.type_) if hasattr(entity, 'type_') else "unknown",
            "mention_text": "",
            "normalized_value": "",
            "confidence": float(entity.confidence) if hasattr(entity, 'confidence') else 0.0,
            "coordinates": [],
            "bounding_box": {}
        }
        
        try:
            # ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
            if hasattr(entity, 'mention_text') and entity.mention_text:
                field_data["mention_text"] = entity.mention_text
            
            # æ­£è¦åŒ–å€¤å–å¾—
            if hasattr(entity, 'normalized_value') and entity.normalized_value:
                if hasattr(entity.normalized_value, 'text'):
                    field_data["normalized_value"] = entity.normalized_value.text
            
            # åº§æ¨™æƒ…å ±å–å¾—ï¼ˆpage_anchorã‹ã‚‰ï¼‰
            if hasattr(entity, 'page_anchor') and entity.page_anchor:
                page_refs = entity.page_anchor.page_refs
                if page_refs and len(page_refs) > 0:
                    page_ref = page_refs[0]
                    if hasattr(page_ref, 'bounding_poly'):
                        bounding_poly = page_ref.bounding_poly
                        if hasattr(bounding_poly, 'normalized_vertices'):
                            coordinates = []
                            for vertex in bounding_poly.normalized_vertices:
                                if hasattr(vertex, 'x') and hasattr(vertex, 'y'):
                                    coordinates.append({
                                        "x": float(vertex.x),
                                        "y": float(vertex.y)
                                    })
                            
                            if len(coordinates) >= 4:
                                field_data["coordinates"] = coordinates
                                field_data["bounding_box"] = {
                                    "left": coordinates[0]["x"],
                                    "top": coordinates[0]["y"],
                                    "right": coordinates[2]["x"],
                                    "bottom": coordinates[2]["y"],
                                    "width": coordinates[2]["x"] - coordinates[0]["x"],
                                    "height": coordinates[2]["y"] - coordinates[0]["y"]
                                }
            
            return field_data if field_data["mention_text"] or field_data["normalized_value"] else None
            
        except Exception as e:
            print(f"âš ï¸ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰{field_num}ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _extract_table_data(self, table, full_text: str, page_num: int, table_num: int) -> Dict[str, Any]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        
        table_data = {
            "page": page_num,
            "table_id": table_num,
            "rows": [],
            "coordinates": [],
            "bounding_box": {}
        }
        
        try:
            # ãƒ†ãƒ¼ãƒ–ãƒ«ã®åº§æ¨™å–å¾—
            if hasattr(table, 'layout') and hasattr(table.layout, 'bounding_poly'):
                bounding_poly = table.layout.bounding_poly
                if hasattr(bounding_poly, 'normalized_vertices'):
                    coordinates = []
                    for vertex in bounding_poly.normalized_vertices:
                        if hasattr(vertex, 'x') and hasattr(vertex, 'y'):
                            coordinates.append({
                                "x": float(vertex.x),
                                "y": float(vertex.y)
                            })
                    
                    if len(coordinates) >= 4:
                        table_data["coordinates"] = coordinates
                        table_data["bounding_box"] = {
                            "left": coordinates[0]["x"],
                            "top": coordinates[0]["y"],
                            "right": coordinates[2]["x"],
                            "bottom": coordinates[2]["y"],
                            "width": coordinates[2]["x"] - coordinates[0]["x"],
                            "height": coordinates[2]["y"] - coordinates[0]["y"]
                        }
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œãƒ‡ãƒ¼ã‚¿å–å¾—
            if hasattr(table, 'header_rows') and table.header_rows:
                for row_idx, row in enumerate(table.header_rows):
                    row_data = self._extract_table_row_data(row, full_text, f"header_{row_idx}")
                    if row_data:
                        table_data["rows"].append(row_data)
            
            if hasattr(table, 'body_rows') and table.body_rows:
                for row_idx, row in enumerate(table.body_rows):
                    row_data = self._extract_table_row_data(row, full_text, f"body_{row_idx}")
                    if row_data:
                        table_data["rows"].append(row_data)
            
            return table_data if table_data["rows"] else None
            
        except Exception as e:
            print(f"âš ï¸ ãƒ†ãƒ¼ãƒ–ãƒ«{table_num}ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _extract_table_row_data(self, row, full_text: str, row_id: str) -> Dict[str, Any]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        
        row_data = {
            "row_id": row_id,
            "cells": []
        }
        
        try:
            if hasattr(row, 'cells') and row.cells:
                for cell_idx, cell in enumerate(row.cells):
                    cell_text = ""
                    if hasattr(cell, 'layout') and hasattr(cell.layout, 'text_anchor'):
                        text_anchor = cell.layout.text_anchor
                        if hasattr(text_anchor, 'text_segments'):
                            for segment in text_anchor.text_segments:
                                start_idx = int(segment.start_index) if hasattr(segment, 'start_index') else 0
                                end_idx = int(segment.end_index) if hasattr(segment, 'end_index') else 0
                                cell_text += full_text[start_idx:end_idx]
                    
                    row_data["cells"].append({
                        "cell_id": cell_idx,
                        "text": cell_text.strip()
                    })
            
            return row_data if row_data["cells"] else None
            
        except Exception as e:
            print(f"âš ï¸ è¡Œ{row_id}ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _extract_text_block_with_coordinates(self, block, full_text: str, page_num: int, block_num: int) -> Dict[str, Any]:
        """ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰åº§æ¨™ä»˜ããƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆDocument OCRã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰"""
        
        block_data = {
            "page": page_num,
            "block_id": block_num,
            "text": "",
            "coordinates": [],
            "bounding_box": {}
        }
        
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹å–å¾—
            if hasattr(block, 'layout') and hasattr(block.layout, 'text_anchor'):
                text_anchor = block.layout.text_anchor
                if hasattr(text_anchor, 'text_segments'):
                    for segment in text_anchor.text_segments:
                        start_idx = int(segment.start_index) if hasattr(segment, 'start_index') else 0
                        end_idx = int(segment.end_index) if hasattr(segment, 'end_index') else 0
                        block_data["text"] += full_text[start_idx:end_idx]
            
            # åº§æ¨™æƒ…å ±å–å¾—
            if hasattr(block, 'layout') and hasattr(block.layout, 'bounding_poly'):
                bounding_poly = block.layout.bounding_poly
                if hasattr(bounding_poly, 'normalized_vertices'):
                    coordinates = []
                    for vertex in bounding_poly.normalized_vertices:
                        if hasattr(vertex, 'x') and hasattr(vertex, 'y'):
                            coordinates.append({
                                "x": float(vertex.x),
                                "y": float(vertex.y)
                            })
                    
                    if len(coordinates) >= 4:
                        block_data["coordinates"] = coordinates
                        block_data["bounding_box"] = {
                            "left": coordinates[0]["x"],
                            "top": coordinates[0]["y"], 
                            "right": coordinates[2]["x"],
                            "bottom": coordinates[2]["y"],
                            "width": coordinates[2]["x"] - coordinates[0]["x"],
                            "height": coordinates[2]["y"] - coordinates[0]["y"]
                        }
            
            return block_data if block_data["text"].strip() else None
            
        except Exception as e:
            print(f"âš ï¸ ãƒ–ãƒ­ãƒƒã‚¯{block_num}ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _extract_text_element_with_coordinates(self, element, full_text: str, page_num: int, elem_num: int, elem_type: str) -> Dict[str, Any]:
        """æ±ç”¨ãƒ†ã‚­ã‚¹ãƒˆè¦ç´ ã‹ã‚‰åº§æ¨™ä»˜ããƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        
        elem_data = {
            "page": page_num,
            "element_id": elem_num,
            "element_type": elem_type,
            "text": "",
            "coordinates": [],
            "bounding_box": {}
        }
        
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹å–å¾—
            if hasattr(element, 'layout') and hasattr(element.layout, 'text_anchor'):
                text_anchor = element.layout.text_anchor
                if hasattr(text_anchor, 'text_segments'):
                    for segment in text_anchor.text_segments:
                        start_idx = int(segment.start_index) if hasattr(segment, 'start_index') else 0
                        end_idx = int(segment.end_index) if hasattr(segment, 'end_index') else 0
                        elem_data["text"] += full_text[start_idx:end_idx]
            
            # åº§æ¨™æƒ…å ±å–å¾—
            if hasattr(element, 'layout') and hasattr(element.layout, 'bounding_poly'):
                bounding_poly = element.layout.bounding_poly
                if hasattr(bounding_poly, 'normalized_vertices'):
                    coordinates = []
                    for vertex in bounding_poly.normalized_vertices:
                        if hasattr(vertex, 'x') and hasattr(vertex, 'y'):
                            coordinates.append({
                                "x": float(vertex.x),
                                "y": float(vertex.y)
                            })
                    
                    if len(coordinates) >= 4:
                        elem_data["coordinates"] = coordinates
                        elem_data["bounding_box"] = {
                            "left": coordinates[0]["x"],
                            "top": coordinates[0]["y"],
                            "right": coordinates[2]["x"],
                            "bottom": coordinates[2]["y"],
                            "width": coordinates[2]["x"] - coordinates[0]["x"],
                            "height": coordinates[2]["y"] - coordinates[0]["y"]
                        }
            
            return elem_data if elem_data["text"].strip() else None
            
        except Exception as e:
            print(f"âš ï¸ {elem_type}{elem_num}ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _extract_visual_element_with_coordinates(self, element, page_num: int, elem_num: int) -> Dict[str, Any]:
        """è¦–è¦šçš„è¦ç´ ã‹ã‚‰åº§æ¨™ä»˜ããƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆDocument OCRã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰"""
        
        elem_data = {
            "page": page_num,
            "element_id": elem_num,
            "type": "unknown",
            "coordinates": [],
            "bounding_box": {}
        }
        
        try:
            # è¦ç´ ã‚¿ã‚¤ãƒ—å–å¾—
            if hasattr(element, 'type'):
                elem_data["type"] = str(element.type).lower()
            
            # åº§æ¨™æƒ…å ±å–å¾—
            if hasattr(element, 'layout') and hasattr(element.layout, 'bounding_poly'):
                bounding_poly = element.layout.bounding_poly
                if hasattr(bounding_poly, 'normalized_vertices'):
                    coordinates = []
                    for vertex in bounding_poly.normalized_vertices:
                        if hasattr(vertex, 'x') and hasattr(vertex, 'y'):
                            coordinates.append({
                                "x": float(vertex.x),
                                "y": float(vertex.y)
                            })
                    
                    if len(coordinates) >= 4:
                        elem_data["coordinates"] = coordinates
                        elem_data["bounding_box"] = {
                            "left": coordinates[0]["x"],
                            "top": coordinates[0]["y"],
                            "right": coordinates[2]["x"], 
                            "bottom": coordinates[2]["y"],
                            "width": coordinates[2]["x"] - coordinates[0]["x"],
                            "height": coordinates[2]["y"] - coordinates[0]["y"]
                        }
            
            return elem_data if elem_data["coordinates"] else None
            
        except Exception as e:
            print(f"âš ï¸ è¦–è¦šè¦ç´ {elem_num}ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _extract_estimated_image_areas_by_keywords(self, page, results: Dict[str, Any], page_num: int, full_text: str):
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã«ã‚ˆã‚‹æ¨å®šç”»åƒã‚¨ãƒªã‚¢æŠ½å‡ºï¼ˆDocument OCRã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰"""
        
        try:
            if not hasattr(page, 'blocks') or not page.blocks:
                print(f"   blockså±æ€§ãªã—")
                return
            
            keyword_blocks_found = 0
            
            for keyword in self.chair_keywords:
                print(f"\n   ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢: '{keyword}'")
                
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¤œç´¢
                matching_blocks = []
                
                for block_idx, block in enumerate(page.blocks):
                    # ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‚’å–å¾—
                    block_text = ""
                    if (hasattr(block, 'layout') and 
                        hasattr(block.layout, 'text_anchor') and
                        block.layout.text_anchor.text_segments):
                        
                        for segment in block.layout.text_anchor.text_segments:
                            start_idx = int(segment.start_index) if hasattr(segment, 'start_index') else 0
                            end_idx = int(segment.end_index) if hasattr(segment, 'end_index') else 0
                            block_text += full_text[start_idx:end_idx]
                    
                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
                    if keyword in block_text:
                        # åº§æ¨™æƒ…å ±ã‚’å–å¾—
                        if (hasattr(block, 'layout') and 
                            hasattr(block.layout, 'bounding_poly') and
                            hasattr(block.layout.bounding_poly, 'normalized_vertices')):
                            
                            vertices = block.layout.bounding_poly.normalized_vertices
                            if len(vertices) >= 4:
                                block_coords = {
                                    'block_idx': block_idx + 1,
                                    'text': block_text.strip(),
                                    'keyword': keyword,
                                    'left': float(vertices[0].x),
                                    'top': float(vertices[0].y),
                                    'right': float(vertices[2].x),
                                    'bottom': float(vertices[2].y)
                                }
                                matching_blocks.append(block_coords)
                                print(f"     âœ… ãƒ–ãƒ­ãƒƒã‚¯{block_idx + 1}ã§ç™ºè¦‹: '{block_text[:30]}...'")
                
                # ãƒãƒƒãƒã—ãŸãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚‹å ´åˆã€æ¨å®šç”»åƒã‚¨ãƒªã‚¢ã‚’ä½œæˆ
                if matching_blocks:
                    for i, match in enumerate(matching_blocks):
                        estimated_area = self._create_estimated_image_area(match, keyword, i + 1)
                        
                        if estimated_area:
                            results["visual_elements"].append(estimated_area)
                            results["summary"]["total_figures"] += 1
                            keyword_blocks_found += 1
                            
                            print(f"     ğŸ“Š æ¨å®šç”»åƒã‚¨ãƒªã‚¢ä½œæˆ: {estimated_area['estimated_type']}")
                            print(f"        åº§æ¨™ç¯„å›²: ({estimated_area['bounding_box']['left']:.3f}, {estimated_area['bounding_box']['top']:.3f}) â†’ ({estimated_area['bounding_box']['right']:.3f}, {estimated_area['bounding_box']['bottom']:.3f})")
                else:
                    print(f"     âŒ '{keyword}' ã‚’å«ã‚€ãƒ–ãƒ­ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            if keyword_blocks_found > 0:
                print(f"\n   ğŸ¯ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢çµæœ: {keyword_blocks_found}å€‹ã®æ¨å®šç”»åƒã‚¨ãƒªã‚¢ã‚’ä½œæˆ")
            else:
                print(f"\n   âš ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã§ã‚‚æ¨å®šã‚¨ãƒªã‚¢ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                
        except Exception as e:
            print(f"   âš ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _create_estimated_image_area(self, text_block: Dict, keyword: str, instance_num: int) -> Optional[Dict[str, Any]]:
        """ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯åº§æ¨™ã‹ã‚‰æ¨å®šç”»åƒã‚¨ãƒªã‚¢ã‚’ä½œæˆï¼ˆDocument OCRã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰"""
        
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã®ä¸­å¿ƒåº§æ¨™ã‚’è¨ˆç®—
            text_center_x = (text_block['left'] + text_block['right']) / 2
            text_center_y = (text_block['top'] + text_block['bottom']) / 2
            
            # ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’é©ç”¨ã—ã¦æ¨å®šã‚¨ãƒªã‚¢ã‚’è¨ˆç®—
            estimated_left = max(0.0, text_center_x - self.area_offset['left'])
            estimated_right = min(1.0, text_center_x + self.area_offset['right'])
            estimated_top = max(0.0, text_center_y - self.area_offset['top'])
            estimated_bottom = min(1.0, text_center_y + self.area_offset['bottom'])
            
            # æ¨å®šç”»åƒã‚¨ãƒªã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            estimated_area = {
                "page": 1,
                "element_id": f"keyword_{keyword}_{instance_num}",
                "type": "estimated_figure",
                "source": "keyword_search",
                "estimated_type": f"{keyword}_area",
                "text_reference": {
                    "block_idx": text_block['block_idx'],
                    "keyword": keyword,
                    "text_content": text_block['text']
                },
                "coordinates": [
                    {"x": estimated_left, "y": estimated_top},
                    {"x": estimated_right, "y": estimated_top},
                    {"x": estimated_right, "y": estimated_bottom},
                    {"x": estimated_left, "y": estimated_bottom}
                ],
                "bounding_box": {
                    "left": estimated_left,
                    "top": estimated_top,
                    "right": estimated_right,
                    "bottom": estimated_bottom,
                    "width": estimated_right - estimated_left,
                    "height": estimated_bottom - estimated_top
                }
            }
            
            return estimated_area
            
        except Exception as e:
            print(f"   âš ï¸ æ¨å®šã‚¨ãƒªã‚¢ä½œæˆã§ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _save_page_image(self, page, page_num: int) -> Optional[Dict[str, Any]]:
        """ãƒšãƒ¼ã‚¸ç”»åƒã‚’Base64ã‹ã‚‰ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦ä¿å­˜"""
        
        try:
            if hasattr(page, 'image') and hasattr(page.image, 'content'):
                # Base64ãƒ‡ã‚³ãƒ¼ãƒ‰
                image_bytes = page.image.content
                image = Image.open(io.BytesIO(image_bytes))
                
                # ç”»åƒä¿å­˜
                filename = f"form_parser_page_{page_num:02d}.png"
                filepath = Path(self.config["output_dir"]) / filename
                image.save(filepath, "PNG")
                
                return {
                    "page": page_num,
                    "filename": filename,
                    "filepath": str(filepath),
                    "width": image.width,
                    "height": image.height,
                    "size_mb": round(len(image_bytes) / 1024 / 1024, 2)
                }
            
            return None
            
        except Exception as e:
            print(f"âš ï¸ ãƒšãƒ¼ã‚¸{page_num}ç”»åƒä¿å­˜ã§ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _extract_figure_images(self, results: Dict[str, Any]):
        """åº§æ¨™æƒ…å ±ã‚’ä½¿ç”¨ã—ã¦ãƒšãƒ¼ã‚¸ç”»åƒã‹ã‚‰å›³è¡¨ã‚’åˆ‡ã‚ŠæŠœã"""
        
        extracted_count = 0
        
        try:
            # å›³è¡¨è¦ç´ ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆæ¨å®šå›³è¡¨ã‚‚å«ã‚€ï¼‰
            figure_elements = [elem for elem in results["visual_elements"] 
                             if elem["type"] in ["figure", "estimated_figure", "potential_image"]]
            
            if not figure_elements:
                print("ğŸ“Š åˆ‡ã‚ŠæŠœãå¯¾è±¡ã®å›³è¡¨ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return
            
            print(f"ğŸ“Š {len(figure_elements)}å€‹ã®å›³è¡¨åˆ‡ã‚ŠæŠœãã‚’é–‹å§‹...")
            print("   å¯¾è±¡ã‚¿ã‚¤ãƒ—:", [elem["type"] for elem in figure_elements])
            
            # ãƒšãƒ¼ã‚¸ç”»åƒã¨å›³è¡¨ã®å¯¾å¿œä»˜ã‘
            for figure in figure_elements:
                page_num = figure["page"]
                
                # å¯¾å¿œã™ã‚‹ãƒšãƒ¼ã‚¸ç”»åƒã‚’æ¤œç´¢
                page_image = next(
                    (img for img in results["page_images"] if img["page"] == page_num), 
                    None
                )
                
                if not page_image:
                    print(f"âš ï¸ ãƒšãƒ¼ã‚¸{page_num}ã®ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    continue
                
                # ç”»åƒåˆ‡ã‚ŠæŠœãå®Ÿè¡Œ
                cropped_info = self._crop_figure_from_page(figure, page_image)
                if cropped_info:
                    results["extracted_figures"].append(cropped_info)
                    extracted_count += 1
                    print(f"âœ… å›³è¡¨åˆ‡ã‚ŠæŠœãæˆåŠŸ: {cropped_info['filename']}")
            
            results["summary"]["total_figures"] = extracted_count
            print(f"ğŸ¯ å›³è¡¨åˆ‡ã‚ŠæŠœãå®Œäº†: {extracted_count}å€‹")
            
        except Exception as e:
            print(f"âŒ å›³è¡¨åˆ‡ã‚ŠæŠœãå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _crop_figure_from_page(self, figure: Dict[str, Any], page_image: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ãƒšãƒ¼ã‚¸ç”»åƒã‹ã‚‰æŒ‡å®šåº§æ¨™ã®å›³è¡¨ã‚’åˆ‡ã‚ŠæŠœã"""
        
        try:
            # ãƒšãƒ¼ã‚¸ç”»åƒã‚’é–‹ã
            page_img = Image.open(page_image["filepath"])
            page_width, page_height = page_img.size
            
            # æ­£è¦åŒ–åº§æ¨™ã‚’å®Ÿéš›ã®ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™ã«å¤‰æ›
            bbox = figure["bounding_box"]
            left = int(bbox["left"] * page_width)
            top = int(bbox["top"] * page_height)
            right = int(bbox["right"] * page_width)
            bottom = int(bbox["bottom"] * page_height)
            
            # åˆ‡ã‚ŠæŠœãå®Ÿè¡Œ
            cropped_img = page_img.crop((left, top, right, bottom))
            
            # ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆForm Parserç”¨ã«å¤‰æ›´ï¼‰
            if figure.get('source') == 'keyword_search':
                filename = f"form_parser_estimated_{figure['estimated_type']}_page{figure['page']:02d}.png"
            else:
                filename = f"form_parser_figure_page{figure['page']:02d}_elem{figure['element_id']}.png"
            
            filepath = Path(self.config["output_dir"]) / filename
            cropped_img.save(filepath, "PNG")
            
            return {
                "page": figure["page"],
                "element_id": figure["element_id"],
                "filename": filename,
                "filepath": str(filepath),
                "original_coordinates": figure["coordinates"],
                "pixel_coordinates": {
                    "left": left,
                    "top": top,
                    "right": right,
                    "bottom": bottom
                },
                "width": right - left,
                "height": bottom - top
            }
            
        except Exception as e:
            print(f"âš ï¸ å›³è¡¨åˆ‡ã‚ŠæŠœãã§ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _display_summary(self, results: Dict[str, Any]):
        """çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        
        print("\n" + "=" * 60)
        print("ğŸ“Š Form Parser è§£æçµæœã‚µãƒãƒªãƒ¼")
        print("=" * 60)
        
        summary = results["summary"]
        
        print(f"ğŸ“„ å…¨æ–‡å­—æ•°: {len(results['full_text']):,}æ–‡å­—")
        print(f"ğŸ“‹ ãƒšãƒ¼ã‚¸æ•°: {summary['total_pages']}å€‹")
        print(f"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯: {summary['total_blocks']}å€‹")
        print(f"ğŸ“ æ®µè½: {summary['total_paragraphs']}å€‹")
        print(f"ğŸ“ è¡Œ: {summary['total_lines']}å€‹")
        print(f"ğŸ”¤ ãƒˆãƒ¼ã‚¯ãƒ³: {summary['total_tokens']}å€‹")
        print(f"ğŸ“‹ ãƒ•ã‚©ãƒ¼ãƒ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: {summary['total_form_fields']}å€‹")
        print(f"ğŸ“Š ãƒ†ãƒ¼ãƒ–ãƒ«: {summary['total_tables']}å€‹")
        print(f"ğŸ¯ åº§æ¨™å–å¾—æˆåŠŸ: {summary['coordinates_found']}å€‹")
        print(f"ğŸ–¼ï¸ å›³è¡¨è¦ç´ : {summary['total_figures']}å€‹")
        print(f"ğŸ’¾ ç”»åƒä¿å­˜: {summary['images_saved']}å€‹")
        
        if results["extracted_figures"]:
            print(f"\nâœ… åˆ‡ã‚ŠæŠœãæˆåŠŸã—ãŸå›³è¡¨:")
            for figure in results["extracted_figures"]:
                print(f"  - {figure['filename']} ({figure['width']}x{figure['height']}px)")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ Google Cloud Document AI - Form Parser")
    print("åŒ…æ‹¬çš„æ–‡æ›¸è§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆDocument OCRæ¯”è¼ƒç”¨ï¼‰")
    print("=" * 60)
    
    processor = FormParserProcessor()
    results = processor.analyze_document_with_form_parser()
    
    if results:
        print("\nğŸ‰ å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {processor.config['output_dir']}")
        print(f"ğŸ“Š Document OCRã¨æ¯”è¼ƒã—ã¦ã”ç¢ºèªãã ã•ã„")
    else:
        print("\nâŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main()